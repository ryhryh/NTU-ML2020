{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://youtu.be/f1KUUz7v8g4?t=3570\n",
    "這裡的regularization是啥 (0.5,0.5)比(0.1,0.9)好\n",
    "假如weight平均分佈，這樣不就都一樣，應該是不想要weight都集中在某個畫面吧\n",
    "\n",
    "- point network: 從input的vec裡面選出一個vec\n",
    "\n",
    "- https://youtu.be/z0uOq2wEGcc?t=634\n",
    "怎麼知道這樣的結構"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GRU裡面的dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T17:26:07.160907Z",
     "start_time": "2020-10-26T17:26:06.211657Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.utils.data.sampler as sampler\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # 判斷是用 CPU 還是 GPU 執行運算\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T17:26:09.578073Z",
     "start_time": "2020-10-26T17:26:09.564446Z"
    }
   },
   "outputs": [],
   "source": [
    "class Options(object):\n",
    "      def __init__(self):\n",
    "        self.batch_size = 60\n",
    "        self.emb_dim = 256\n",
    "        self.hid_dim = 512\n",
    "        self.n_layers = 3\n",
    "        self.dropout = 0.5\n",
    "        self.learning_rate = 0.00005\n",
    "        self.seq_len = 50              # 最後輸出句子的最大長度\n",
    "        self.num_steps = 12000                # 總訓練次數\n",
    "        self.store_steps = 300                # 訓練多少次後須儲存模型\n",
    "        self.summary_steps = 300              # 訓練多少次後須檢驗是否有overfitting\n",
    "        self.load_model = False               # 是否需載入模型\n",
    "        self.store_model_path = \"./ckpt\"      # 儲存模型的位置\n",
    "        self.load_model_path = None           # 載入模型的位置 e.g. \"./ckpt/model_{step}\" \n",
    "        self.data_dir = '/workdir/home/feynman52/NTU-ML2020/hw8-Seq2seq/datasets/cmn-eng/'          # 資料存放的位置\n",
    "        self.attention = False                # 是否使用 Attention Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T08:56:12.257046Z",
     "start_time": "2020-10-26T08:56:12.235510Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "options = Options()\n",
    "options.num_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## int2str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T17:26:11.646133Z",
     "start_time": "2020-10-26T17:26:11.634751Z"
    }
   },
   "outputs": [],
   "source": [
    "def intSen2strSen(intSen, int2word):\n",
    "    strSen = []\n",
    "    for x in intSen:\n",
    "        word = int2word[str(int(x))]\n",
    "        if word == '<EOS>': break\n",
    "        strSen.append(word)\n",
    "    return strSen\n",
    "\n",
    "def intSens2strSens(intSens, int2word):\n",
    "    strSens = [intSen2strSen(intSen, int2word) for intSen in intSens] \n",
    "    return strSens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T09:58:03.429994Z",
     "start_time": "2020-10-26T09:58:03.421037Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 5\n",
    "print(intSen2strSen(x[i], train_set.int2word_en))\n",
    "print(intSen2strSen(y[i], train_set.int2word_cn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T06:55:50.892857Z",
     "start_time": "2020-10-26T06:55:50.887111Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class LabelTransform(object):\n",
    "    def __init__(self, size, pad):\n",
    "        self.size = size\n",
    "        self.pad = pad\n",
    "\n",
    "    def __call__(self, label):\n",
    "        label = np.pad(label, (0, (self.size - label.shape[0])), mode='constant', constant_values=self.pad)\n",
    "        return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T06:55:50.948391Z",
     "start_time": "2020-10-26T06:55:50.895305Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "class EN2CNDataset(data.Dataset):\n",
    "    def __init__(self, root, max_output_len, set_name):\n",
    "        self.root = root\n",
    "\n",
    "        self.word2int_cn, self.int2word_cn = self.get_dictionary('cn')\n",
    "        self.word2int_en, self.int2word_en = self.get_dictionary('en')\n",
    "\n",
    "        # 載入資料\n",
    "        self.data = []\n",
    "        with open(os.path.join(self.root, f'{set_name}.txt'), \"r\") as f:\n",
    "            for line in f:\n",
    "                self.data.append(line)\n",
    "        print (f'{set_name} dataset size: {len(self.data)}')\n",
    "\n",
    "        self.cn_vocab_size = len(self.word2int_cn)\n",
    "        self.en_vocab_size = len(self.word2int_en)\n",
    "        self.transform = LabelTransform(max_output_len, self.word2int_en['<PAD>'])\n",
    "\n",
    "    def get_dictionary(self, language):\n",
    "        # 載入字典\n",
    "        with open(os.path.join(self.root, f'word2int_{language}.json'), \"r\") as f:\n",
    "            word2int = json.load(f)\n",
    "        with open(os.path.join(self.root, f'int2word_{language}.json'), \"r\") as f:\n",
    "            int2word = json.load(f)\n",
    "            return word2int, int2word\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, Index):\n",
    "        print('#'*50)\n",
    "        # 先將中英文分開\n",
    "        sentences = self.data[Index]\n",
    "        print(sentences)\n",
    "        sentences = re.split('[\\t\\n]', sentences)\n",
    "        print(sentences)\n",
    "        sentences = list(filter(None, sentences))\n",
    "        print(sentences)\n",
    "        #print (sentences)\n",
    "        assert len(sentences) == 2\n",
    "\n",
    "        # 預備特殊字元\n",
    "        BOS = self.word2int_en['<BOS>']\n",
    "        EOS = self.word2int_en['<EOS>']\n",
    "        UNK = self.word2int_en['<UNK>']\n",
    "\n",
    "        print('#'*50)\n",
    "        # 在開頭添加 <BOS>，在結尾添加 <EOS> ，不在字典的 subword (詞) 用 <UNK> 取代\n",
    "        en, cn = [BOS], [BOS]\n",
    "        # 將句子拆解為 subword 並轉為整數\n",
    "        sentence = re.split(' ', sentences[0])\n",
    "        print(sentence)\n",
    "        sentence = list(filter(None, sentence)) # https://stackoverflow.com/questions/3845423/remove-empty-strings-from-a-list-of-strings\n",
    "        print(sentence)\n",
    "        #print (f'en: {sentence}')\n",
    "        for word in sentence:\n",
    "            en.append(self.word2int_en.get(word, UNK))\n",
    "        en.append(EOS)\n",
    "        print(en)\n",
    "\n",
    "        print('#'*50)\n",
    "        # 將句子拆解為單詞並轉為整數\n",
    "        # e.g. < BOS >, we, are, friends, < EOS > --> 1, 28, 29, 205, 2\n",
    "        sentence = re.split(' ', sentences[1])\n",
    "        print(sentence)\n",
    "        sentence = list(filter(None, sentence))\n",
    "        print(sentence)\n",
    "        #print (f'cn: {sentence}')\n",
    "        for word in sentence:\n",
    "            cn.append(self.word2int_cn.get(word, UNK))\n",
    "        cn.append(EOS)\n",
    "        print(cn)\n",
    "\n",
    "        en, cn = np.asarray(en), np.asarray(cn)\n",
    "\n",
    "        # 用 <PAD> 將句子補到相同長度\n",
    "        en, cn = self.transform(en), self.transform(cn)\n",
    "        en, cn = torch.LongTensor(en), torch.LongTensor(cn)\n",
    "\n",
    "        return en, cn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## check file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T06:55:51.039133Z",
     "start_time": "2020-10-26T06:55:50.952904Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "root = '/workdir/home/feynman52/NTU-ML2020/hw8-Seq2seq/datasets/cmn-eng'\n",
    "max_output_len = 20\n",
    "set_name = 'training'\n",
    "eN2CNDataset = EN2CNDataset(root, max_output_len, set_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T06:55:51.084644Z",
     "start_time": "2020-10-26T06:55:51.041108Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "list(filter(None, ['what', 'exactly', 'does', 'tom', 'do', '?', '']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T06:55:51.126252Z",
     "start_time": "2020-10-26T06:55:51.087514Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# encoder biriectional => padding在後面沒差!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T06:55:51.186665Z",
     "start_time": "2020-10-26T06:55:51.129725Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "(eN2CNDataset[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T06:55:51.266729Z",
     "start_time": "2020-10-26T06:55:51.190703Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "eN2CNDataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T06:55:51.341285Z",
     "start_time": "2020-10-26T06:55:51.274932Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('/workdir/home/feynman52/NTU-ML2020/hw8-Seq2seq/datasets/cmn-eng/int2word_cn.json', \"r\") as f:\n",
    "    int2word_cn = json.load(f)\n",
    "    \n",
    "int2word_cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T06:55:51.385910Z",
     "start_time": "2020-10-26T06:55:51.343868Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('/workdir/home/feynman52/NTU-ML2020/hw8-Seq2seq/datasets/cmn-eng/word2int_cn.json', \"r\") as f:\n",
    "    word2int = json.load(f)\n",
    "    \n",
    "word2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T06:55:51.452980Z",
     "start_time": "2020-10-26T06:55:51.387732Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('/workdir/home/feynman52/NTU-ML2020/hw8-Seq2seq/datasets/cmn-eng/training.txt', 'r') as f:\n",
    "    content = f.readlines()\n",
    "    \n",
    "content = [x.strip() for x in content]     \n",
    "content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T06:55:51.486722Z",
     "start_time": "2020-10-26T06:55:51.455046Z"
    }
   },
   "outputs": [],
   "source": [
    "cn = [1,2,3,4,5]\n",
    "cn += ['<PAD>'] * (3 - len(cn))\n",
    "print(cn)\n",
    "\n",
    "cn = [1,2,3,4,5]\n",
    "cn += ['<PAD>'] * (8 - len(cn))\n",
    "print(cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T06:55:51.534683Z",
     "start_time": "2020-10-26T06:55:51.491025Z"
    }
   },
   "outputs": [],
   "source": [
    "# np.pad([4,5,6], (0, -2), mode='constant', constant_values=(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T17:26:14.893955Z",
     "start_time": "2020-10-26T17:26:14.863314Z"
    }
   },
   "outputs": [],
   "source": [
    "class Seq2seqDataset(data.Dataset):\n",
    "    def __init__(self, data_dir=None, which_dataset='testing.txt', seq_len=20):\n",
    "        self.data_dir = data_dir\n",
    "        self.which_dataset = which_dataset\n",
    "        self.seq_len = seq_len\n",
    "        self.setup()\n",
    "        \n",
    "    def setup(self):\n",
    "        self.setup_dict()\n",
    "        self.setup_data()\n",
    "    \n",
    "    def setup_dict(self):\n",
    "        self.int2word_cn = self.load_json('int2word_cn.json') \n",
    "        self.int2word_en = self.load_json('int2word_en.json') \n",
    "        \n",
    "        self.word2int_cn = self.load_json('word2int_cn.json') \n",
    "        self.word2int_en = self.load_json('word2int_en.json') \n",
    "        \n",
    "        self.cn_dict_size = len(self.int2word_cn)\n",
    "        self.en_dict_size = len(self.int2word_en)\n",
    "    \n",
    "    def load_json(self, path):\n",
    "        with open(os.path.join(self.data_dir, path), \"r\") as f:\n",
    "            j = json.load(f)\n",
    "        return j\n",
    "    \n",
    "    def setup_data(self):\n",
    "        with open(os.path.join(self.data_dir, self.which_dataset), \"r\") as f:\n",
    "            self.data = f.readlines()\n",
    "        self.sentences_en = []\n",
    "        self.sentences_cn = []\n",
    "        for en_cn in self.data:\n",
    "            en, cn = en_cn.replace(' \\n', '').split(' \\t')\n",
    "            en = self.process_word2int(en, self.word2int_en)\n",
    "            cn = self.process_word2int(cn, self.word2int_cn)\n",
    "            self.sentences_en.append(en)\n",
    "            self.sentences_cn.append(cn)\n",
    "            \n",
    "    def process_word2int(self, cn, word2int_cn):\n",
    "        cn = cn.split(' ') \n",
    "        cn = ['<BOS>'] + cn + ['<EOS>']\n",
    "        cn += ['<PAD>'] * (self.seq_len - len(cn)) # 因為encoder是bi-direction, 所以padding在前面後面沒差\n",
    "        cn = cn[:self.seq_len] # 假如字超過seq_len，取前一部份的長度\n",
    "        cn = [word2int_cn[x] if x in word2int_cn else word2int_cn['<UNK>'] for x in cn]\n",
    "        cn = torch.LongTensor(cn)\n",
    "        return cn\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        #print(self.data[index])\n",
    "        sentence_en = self.sentences_en[index]\n",
    "        sentence_cn = self.sentences_cn[index]\n",
    "        return sentence_en, sentence_cn\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T09:43:18.187112Z",
     "start_time": "2020-10-26T09:43:17.610893Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dir = '/workdir/home/feynman52/NTU-ML2020/hw8-Seq2seq/datasets/cmn-eng/'\n",
    "train_set = Seq2seqDataset(data_dir, which_dataset='training.txt')\n",
    "valid_set = Seq2seqDataset(data_dir, which_dataset='validation.txt')\n",
    "test_set = Seq2seqDataset(data_dir, which_dataset='testing.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T06:55:52.163135Z",
     "start_time": "2020-10-26T06:55:52.160148Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# en_cn = seq2seqDataset.data[0]\n",
    "# en, cn = en_cn.replace(' \\n', '').split(' \\t')\n",
    "\n",
    "# word2int_cn = seq2seqDataset.word2int_cn\n",
    "# int2word_cn = seq2seqDataset.int2word_cn\n",
    "# cn = cn.split(' ') \n",
    "# print(cn)\n",
    "# cn = ['<BOS>'] + cn + ['<EOS>']\n",
    "# cn += ['<PAD>'] * (seq2seqDataset.seq_len - len(cn))\n",
    "# cn = [word2int_cn[x] if x in word2int_cn else word2int_cn['<UNK>'] for x in cn]\n",
    "# print(cn)\n",
    "# cn_reverse = [int2word_cn[str(x)] for x in cn]\n",
    "# print(len(cn_reverse))\n",
    "# cn_reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T09:43:20.668102Z",
     "start_time": "2020-10-26T09:43:20.658012Z"
    }
   },
   "outputs": [],
   "source": [
    "len(train_set), len(valid_set), len(test_set), "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T09:44:29.107535Z",
     "start_time": "2020-10-26T09:44:29.098373Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "train_loader = data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = data.DataLoader(valid_set, batch_size=batch_size, shuffle=False)\n",
    "test_loader = data.DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T09:44:30.827649Z",
     "start_time": "2020-10-26T09:44:30.818139Z"
    }
   },
   "outputs": [],
   "source": [
    "len(train_loader), len(valid_loader), len(test_loader), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T09:44:35.914512Z",
     "start_time": "2020-10-26T09:44:35.899293Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "print(x.shape, y.shape)\n",
    "print(x[0], y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T09:44:48.366443Z",
     "start_time": "2020-10-26T09:44:48.354131Z"
    }
   },
   "outputs": [],
   "source": [
    "#? 為啥test data也有y\n",
    "x, y = next(iter(test_loader))\n",
    "print(x.shape, y.shape)\n",
    "print(x[0], y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T11:20:48.006986Z",
     "start_time": "2020-10-26T11:20:47.992650Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, en_vocab_size, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(en_vocab_size, emb_dim)\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.rnn = nn.GRU(emb_dim, hid_dim, n_layers, dropout=dropout, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # input = [batch size, sequence len, vocab size]\n",
    "        embedding = self.embedding(input)\n",
    "        output, h_n = self.rnn(self.dropout(embedding))\n",
    "        # output of shape (batch, seq_len, num_directions * hidden_size)\n",
    "        # h_n of shape (batch, num_layers * num_directions, hidden_size)\n",
    "\n",
    "        return output, h_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T11:20:49.561870Z",
     "start_time": "2020-10-26T11:20:49.538905Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, cn_vocab_size, emb_dim, hid_dim, n_layers, dropout, isatt):\n",
    "        super().__init__()\n",
    "        self.cn_vocab_size = cn_vocab_size\n",
    "        self.hid_dim = hid_dim * 2\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(cn_vocab_size, config.emb_dim)\n",
    "        self.isatt = isatt\n",
    "        self.attention = Attention(hid_dim)\n",
    "        \n",
    "        # 如果使用 Attention Mechanism 會使得輸入維度變化，請在這裡修改\n",
    "        # e.g. Attention 接在輸入後面會使得維度變化，所以輸入維度改為\n",
    "        # self.input_dim = emb_dim + hid_dim * 2 if isatt else emb_dim\n",
    "        self.input_dim = emb_dim\n",
    "        \n",
    "        self.rnn = nn.GRU(self.input_dim, self.hid_dim, self.n_layers, dropout = dropout, batch_first=True)\n",
    "        self.embedding2vocab1 = nn.Linear(self.hid_dim, self.hid_dim * 2)\n",
    "        self.embedding2vocab2 = nn.Linear(self.hid_dim * 2, self.hid_dim * 4)\n",
    "        self.embedding2vocab3 = nn.Linear(self.hid_dim * 4, self.cn_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        # input = [batch size, vocab size] ### (50, 20) 這邊應該寫錯了，這裡是 (batch, seq_len)\n",
    "        # hidden = [batch size, n layers * directions, hid dim]\n",
    "        # Decoder 只會是單向，所以 directions=1\n",
    "        input = input.unsqueeze(1)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        # embedded = [batch size, 1, emb dim]\n",
    "        \n",
    "        if self.isatt:\n",
    "            attn = self.attention(encoder_outputs, hidden)\n",
    "            # TODO: 在這裡決定如何使用 Attention，e.g. 相加 或是 接在後面， 請注意維度變化\n",
    "            \n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        # output = [batch size, 1, hid dim]\n",
    "        # hidden = [batch size, num_layers, hid dim]\n",
    "\n",
    "        # 將 RNN 的輸出轉為每個詞出現的機率\n",
    "        output = self.embedding2vocab1(output.squeeze(1))\n",
    "        output = self.embedding2vocab2(output)\n",
    "        prediction = self.embedding2vocab3(output)\n",
    "        # prediction = [batch size, cn_vocab_size]\n",
    "        return prediction, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T11:20:51.832905Z",
     "start_time": "2020-10-26T11:20:51.822609Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hid_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.hid_dim = hid_dim\n",
    "\n",
    "    def forward(self, encoder_outputs, decoder_hidden):\n",
    "        # encoder_outputs = [batch size, sequence len, hid dim * directions]\n",
    "        # decoder_hidden = [num_layers, batch size, hid dim]\n",
    "        # 一般來說是取 Encoder 最後一層的 hidden state 來做 attention\n",
    "        ########\n",
    "        # TODO #\n",
    "        ########\n",
    "        attention=None\n",
    "\n",
    "        return attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T11:20:54.169980Z",
     "start_time": "2020-10-26T11:20:54.139321Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "                \"Encoder and decoder must have equal number of layers!\"\n",
    "\n",
    "    def forward(self, input, target, teacher_forcing_ratio):\n",
    "        # input  = [batch size, input len, vocab size]\n",
    "        # target = [batch size, target len, vocab size]\n",
    "        # teacher_forcing_ratio 是有多少機率使用正確答案來訓練\n",
    "        batch_size = target.shape[0]\n",
    "        target_len = target.shape[1]\n",
    "        vocab_size = self.decoder.cn_vocab_size\n",
    "\n",
    "        # 準備一個儲存空間來儲存輸出\n",
    "        outputs = torch.zeros(batch_size, target_len, vocab_size).to(self.device)\n",
    "        \n",
    "        # 將輸入放入 Encoder\n",
    "        encoder_outputs, hidden = self.encoder(input)\n",
    "        \n",
    "        # Encoder 最後的隱藏層(hidden state) 用來初始化 Decoder\n",
    "        # encoder_outputs 主要是使用在 Attention\n",
    "        # 因為 Encoder 是雙向的RNN，所以需要將同一層兩個方向的 hidden state 接在一起\n",
    "        # hidden =  [num_layers * directions, batch size  , hid dim]  --> [num_layers, directions, batch size  , hid dim]\n",
    "        hidden = hidden.view(self.encoder.n_layers, 2, batch_size, -1)\n",
    "        hidden = torch.cat((hidden[:, -2, :, :], hidden[:, -1, :, :]), dim=2) ###\n",
    "        \n",
    "        # 取得 <BOS> token\n",
    "        input = target[:, 0] ###\n",
    "        preds = []\n",
    "        for t in range(1, target_len):\n",
    "            output, hidden = self.decoder(input, hidden, encoder_outputs)\n",
    "            outputs[:, t] = output ### [batch, cn_vocab_size]\n",
    "            \n",
    "            # 決定是否用正確答案來做訓練\n",
    "            teacher_force = (random.random() <= teacher_forcing_ratio)\n",
    "            \n",
    "            # 取出機率最大的單詞\n",
    "            top1 = output.argmax(1)\n",
    "            \n",
    "            # 如果是 teacher force 則用正解訓練，反之用自己預測的單詞做預測\n",
    "            input = target[:, t] if teacher_force and t < target_len else top1\n",
    "            preds.append(top1.unsqueeze(1))\n",
    "        preds = torch.cat(preds, 1)\n",
    "        return outputs, preds\n",
    "\n",
    "    def inference(self, input, target):\n",
    "        ########\n",
    "        # TODO #\n",
    "        ########\n",
    "        # 在這裡實施 Beam Search\n",
    "        # 此函式的 batch size = 1  \n",
    "        # input  = [batch size, input len, vocab size]\n",
    "        # target = [batch size, target len, vocab size]\n",
    "        batch_size = input.shape[0]\n",
    "        input_len = input.shape[1]        # 取得最大字數\n",
    "        vocab_size = self.decoder.cn_vocab_size\n",
    "\n",
    "        # 準備一個儲存空間來儲存輸出\n",
    "        outputs = torch.zeros(batch_size, input_len, vocab_size).to(self.device)\n",
    "        # 將輸入放入 Encoder\n",
    "        encoder_outputs, hidden = self.encoder(input)\n",
    "        # Encoder 最後的隱藏層(hidden state) 用來初始化 Decoder\n",
    "        # encoder_outputs 主要是使用在 Attention\n",
    "        # 因為 Encoder 是雙向的RNN，所以需要將同一層兩個方向的 hidden state 接在一起\n",
    "        # hidden =  [num_layers * directions, batch size  , hid dim]  --> [num_layers, directions, batch size  , hid dim]\n",
    "        hidden = hidden.view(self.encoder.n_layers, 2, batch_size, -1)\n",
    "        hidden = torch.cat((hidden[:, -2, :, :], hidden[:, -1, :, :]), dim=2)\n",
    "        # 取的 <BOS> token\n",
    "        input = target[:, 0]\n",
    "        preds = []\n",
    "        for t in range(1, input_len):\n",
    "            output, hidden = self.decoder(input, hidden, encoder_outputs)\n",
    "            # 將預測結果存起來\n",
    "            outputs[:, t] = output\n",
    "            # 取出機率最大的單詞\n",
    "            top1 = output.argmax(1)\n",
    "            input = top1\n",
    "            preds.append(top1.unsqueeze(1))\n",
    "        preds = torch.cat(preds, 1)\n",
    "        return outputs, preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EncoderModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T17:26:21.763142Z",
     "start_time": "2020-10-26T17:26:21.746472Z"
    }
   },
   "outputs": [],
   "source": [
    "class EncoderModel(nn.Module):\n",
    "    def __init__(self, en_dict_size=10000, dropout=0.2, enc_h_dim=10, embedding_dim=20, num_layers=5):\n",
    "        super().__init__()\n",
    "        self.en_dict_size = en_dict_size\n",
    "        self.enc_h_dim = enc_h_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings=en_dict_size, \n",
    "                                      embedding_dim=embedding_dim)\n",
    "        \n",
    "        self.gru = nn.GRU(input_size=embedding_dim, \n",
    "                          hidden_size=enc_h_dim, \n",
    "                          num_layers=num_layers, \n",
    "                          bias=True, \n",
    "                          batch_first=True, \n",
    "                          dropout=dropout, \n",
    "                          bidirectional=True)\n",
    "        \n",
    "    def forward(self, enc_input): \n",
    "        egru_input = self.embedding(enc_input) # (batch, seq_len) => (batch, seq_len, embedding_dim)\n",
    "        \n",
    "        egru_output, egru_hidden = self.gru(egru_input)\n",
    "        # egru_output = (batch, seq_len, num_directions * hidden_size) = (batch, seq_len, 2 * enc_h_dim)\n",
    "        # egru_hidden = (num_layers * num_directions, batch, hidden_size) = (num_layers * 2, batch, enc_h_dim)\n",
    "        \n",
    "        return egru_output, egru_hidden\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AttentionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T17:26:19.832452Z",
     "start_time": "2020-10-26T17:26:19.822817Z"
    }
   },
   "outputs": [],
   "source": [
    "class AttentionModel(nn.Module):\n",
    "    def __init__(self, hid_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.hid_dim = hid_dim\n",
    "\n",
    "    def forward(self, dgru_hidden, egru_output):\n",
    "        # egru_output = (batch, seq_len, 2*enc_h_dim)\n",
    "        # dgru_hidden = (num_layers, batch, enc_h_dim*2)\n",
    "        \n",
    "        attention = None # (batch, 2*enc_h_dim) #?\n",
    "\n",
    "        return attention # (batch, 1, 2*enc_h_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecoderModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T17:26:24.156224Z",
     "start_time": "2020-10-26T17:26:24.135501Z"
    }
   },
   "outputs": [],
   "source": [
    "class DecoderModel(nn.Module):\n",
    "    def __init__(self, cn_dict_size=10000, dropout=0.2, enc_h_dim=10, embedding_dim=20, num_layers=5):\n",
    "        super().__init__() \n",
    "        self.dec_h_dim = enc_h_dim*2\n",
    "        self.cn_dict_size = cn_dict_size\n",
    "        self.enc_h_dim = enc_h_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.dgru_input_dim = embedding_dim +  enc_h_dim*2 #?\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings=cn_dict_size, \n",
    "                                      embedding_dim=embedding_dim)\n",
    "        \n",
    "        self.gru = nn.GRU(input_size=self.dgru_input_dim, \n",
    "                          hidden_size=self.dec_h_dim, \n",
    "                          num_layers=num_layers, \n",
    "                          bias=True, \n",
    "                          batch_first=True, \n",
    "                          dropout=dropout, \n",
    "                          bidirectional=False)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.dnn1 = nn.Linear(self.dec_h_dim, self.dec_h_dim * 2)\n",
    "        self.dnn2 = nn.Linear(self.dec_h_dim * 2, self.dec_h_dim * 4)\n",
    "        self.dnn3 = nn.Linear(self.dec_h_dim * 4, cn_dict_size)\n",
    "        \n",
    "    def forward(self, dec_input, dgru_hidden, egru_output):         \n",
    "        x = self.embedding(dec_input) # (batch, 1) => (batch, 1, emb_dim)\n",
    "        x = self.dropout(x) # (batch, 1, emb_dim) \n",
    "        \n",
    "        attention = self.AttentionModel() # (batch, 1, 2*enc_h_dim)\n",
    "        dgru_input = concat([x, attention], dim=2) # (batch, 1, emb_dim + 2*enc_h_dim)\n",
    "        \n",
    "        dgru_output, dgru_hidden = self.gru(dgru_input, dgru_hidden) \n",
    "        # dgru_output = (batch, seq_len, num_directions * hidden_size) = (batch, 1, dec_h_dim)\n",
    "        # dgru_hidden = (num_layers * num_directions, batch, hidden_size) = (num_layers, batch, dec_h_dim)\n",
    "        \n",
    "        dec_output = dgru_output.squeeze(1) # (batch, dec_h_dim)\n",
    "        dec_output = self.dnn1(dec_output)\n",
    "        dec_output = self.dnn2(dec_output)\n",
    "        dec_output = self.dnn3(dec_output) # (batch, cn_dict_size)\n",
    "        return dec_output, dgru_hidden\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T06:55:52.811972Z",
     "start_time": "2020-10-26T06:55:52.752040Z"
    }
   },
   "outputs": [],
   "source": [
    "# x = torch.zeros(50, 20)\n",
    "# print(x.shape)\n",
    "# x = x[:, 10:11]\n",
    "# print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T06:55:52.867542Z",
     "start_time": "2020-10-26T06:55:52.818370Z"
    }
   },
   "outputs": [],
   "source": [
    "# x = torch.zeros(50, 20)\n",
    "# print(x.shape)\n",
    "# x = x[:, 10]\n",
    "# print(x.shape)\n",
    "# x = x.unsqueeze(1)\n",
    "# print(x.shape)\n",
    "# x = x.squeeze(1)\n",
    "# print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T06:55:52.925450Z",
     "start_time": "2020-10-26T06:55:52.870735Z"
    }
   },
   "outputs": [],
   "source": [
    "# x = torch.zeros(50, 1, 15)\n",
    "# print(x.shape)\n",
    "# x = x.squeeze(1)\n",
    "# print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2seqModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T17:26:26.970462Z",
     "start_time": "2020-10-26T17:26:26.939585Z"
    }
   },
   "outputs": [],
   "source": [
    "class Seq2seqModel(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, enc_input, target, teacher_forcing_ratio):\n",
    "        batch_size = enc_input.shape[0]\n",
    "        seq_len = enc_input.shape[1]\n",
    "        \n",
    "        egru_output, egru_hidden = self.encoder(enc_input)\n",
    "        # enc_input = (batch, seq_len)\n",
    "        # egru_output = (batch, seq_len, num_directions * hidden_size) = (batch, seq_len, 2 * enc_h_dim)\n",
    "        # egru_hidden = (num_layers * num_directions, batch, hidden_size) = (num_layers * 2, batch, enc_h_dim)\n",
    "        \n",
    "        egru_hidden = egru_hidden.reshape(self.encoder.num_layers, 2, batch_size, self.encoder.enc_h_dim) \n",
    "        # batch_first不影響hidden的shape, (num_layers, 2, batch, enc_h_dim) \n",
    "        \n",
    "        dgru_hidden = torch.cat([egru_hidden[:,0,:,:], egru_hidden[:,1,:,:]], dim=2) \n",
    "        # [(num_layers, batch, enc_h_dim)] => (num_layers, batch, enc_h_dim*2)\n",
    "        \n",
    "        dec_input = target[:, 0:1] # (batch, seq_len) => (batch, 1)\n",
    "        \n",
    "        one_hot_outputs = torch.zeros(batch_size, seq_len, self.decoder.cn_dict_size).to(self.device) \n",
    "        # (batch, seq_len, cn_dict_size)\n",
    "        \n",
    "        int_outputs = [] \n",
    "        for i in range(1, seq_len):\n",
    "            dec_output, dgru_hidden = self.decoder(dec_input, dgru_hidden, egru_output)\n",
    "            # dec_output = (batch, cn_dict_size)\n",
    "            # dgru_hidden = (num_layers, batch, dec_h_dim)\n",
    "            \n",
    "            one_hot_outputs[:, i, :] = dec_output \n",
    "            \n",
    "            top1 = one_hot_outputs.argmax(dim=1) # (batch, cn_dict_size) => (batch,)\n",
    "            top1 = top1.unsqueeze(dim=1) # (batch, 1)\n",
    "            int_outputs.append(top1) # [(batch, 1)]\n",
    "            \n",
    "            dec_input = target[:, i:i+1] if random.random() <= teacher_forcing_ratio else top1\n",
    "            \n",
    "        int_outputs = torch.cat(int_outputs, dim=1) # (batch, seq_len)\n",
    "        \n",
    "        return one_hot_outputs, int_outputs\n",
    "    \n",
    "    def inference(self, enc_input, target):\n",
    "        batch_size = enc_input.shape[0]\n",
    "        seq_len = enc_input.shape[1]\n",
    "        \n",
    "        enc_output, enc_hidden = self.encoder(enc_input)\n",
    "        \n",
    "        enc_hidden = enc_hidden.reshape(self.encoder.num_layers, 2, batch_size, self.encoder.enc_h_dim) \n",
    "        # batch_first不影響hidden的shape\n",
    "        # (num_layers * num_directions, batch, hidden_size) => (num_layers, num_directions, batch, hidden_size) \n",
    "        \n",
    "        enc_hidden = torch.cat([enc_hidden[:,0,:,:], enc_hidden[:,1,:,:]], dim=2) # [(num_layers, batch, hidden_size)] => (num_layers, batch, hidden_size*2)\n",
    "        dec_hidden = enc_hidden\n",
    "        \n",
    "        #? 這裡應該不需要target才對，直接輸入BOS就好\n",
    "        dec_input = target[:, 0:1] # (batch, seq_len) => (batch, 1) \n",
    "        dec_outputs = torch.zeros(batch_size, seq_len, self.decoder.cn_dict_size).to(self.device) # (batch, seq_len, cn_dict_size)\n",
    "        seq_outputs = [] \n",
    "        for i in range(1, seq_len):\n",
    "            dec_output, dec_hidden = self.decoder(dec_input, dec_hidden, enc_output)\n",
    "            \n",
    "            dec_outputs[:, i] = dec_output # (batch, cn_dict_size)\n",
    "            \n",
    "            top1 = dec_output.argmax(dim=1) # (batch, cn_dict_size) => (batch,)\n",
    "            top1 = top1.unsqueeze(dim=1) # (batch, 1)\n",
    "            seq_outputs.append(top1)\n",
    "            \n",
    "            dec_input = top1\n",
    "            \n",
    "        seq_outputs = torch.cat(seq_outputs, dim=1) # [(batch, 1)] => (batch, seq_len)\n",
    "        \n",
    "        return dec_outputs, seq_outputs\n",
    "        \n",
    "                \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T06:55:53.062177Z",
     "start_time": "2020-10-26T06:55:52.989272Z"
    }
   },
   "outputs": [],
   "source": [
    "# x = torch.zeros(50, 4)\n",
    "# y = torch.zeros(23, 4)\n",
    "# z = torch.cat([x, y], dim=0)\n",
    "# z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T06:55:53.117240Z",
     "start_time": "2020-10-26T06:55:53.066515Z"
    }
   },
   "outputs": [],
   "source": [
    "# a = torch.randn(2,4)\n",
    "# print(a, a.shape)\n",
    "# b = torch.argmax(a, dim=1)\n",
    "# print(b, b.shape)\n",
    "# b = b.unsqueeze(dim=1)\n",
    "# print(b, b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T08:56:14.644609Z",
     "start_time": "2020-10-26T08:56:14.635235Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T06:55:53.969158Z",
     "start_time": "2020-10-26T06:55:53.316325Z"
    }
   },
   "outputs": [],
   "source": [
    "train_set = Seq2seqDataset(options.data_dir, which_dataset='training.txt')\n",
    "valid_set = Seq2seqDataset(options.data_dir, which_dataset='validation.txt')\n",
    "test_set = Seq2seqDataset(options.data_dir, which_dataset='testing.txt')\n",
    "train_set.cn_dict_size, train_set.en_dict_size, \n",
    "len(train_set), len(valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T06:55:54.019485Z",
     "start_time": "2020-10-26T06:55:53.971728Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(train_set, batch_size=options.batch_size, shuffle=True)\n",
    "valid_loader = data.DataLoader(valid_set, batch_size=options.batch_size, shuffle=False)\n",
    "test_loader = data.DataLoader(test_set, batch_size=options.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T07:01:16.281247Z",
     "start_time": "2020-10-26T07:01:16.272286Z"
    }
   },
   "outputs": [],
   "source": [
    "len(train_set), options.batch_size, len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T06:55:54.201602Z",
     "start_time": "2020-10-26T06:55:54.021396Z"
    }
   },
   "outputs": [],
   "source": [
    "encoderModel = EncoderModel(en_dict_size=train_set.en_dict_size, \n",
    "                            dropout=options.dropout, \n",
    "                            enc_h_dim=options.hid_dim, \n",
    "                            embedding_dim=options.emb_dim, \n",
    "                            num_layers=options.n_layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T06:55:54.624146Z",
     "start_time": "2020-10-26T06:55:54.203479Z"
    }
   },
   "outputs": [],
   "source": [
    "decoderModel = DecoderModel(cn_dict_size=train_set.cn_dict_size, \n",
    "                            dropout=options.dropout, \n",
    "                            enc_h_dim=options.hid_dim, \n",
    "                            embedding_dim=options.emb_dim, \n",
    "                            num_layers=options.n_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T06:55:59.524387Z",
     "start_time": "2020-10-26T06:55:54.626180Z"
    }
   },
   "outputs": [],
   "source": [
    "seq2seqModel = Seq2seqModel(encoderModel, decoderModel, device)\n",
    "seq2seqModel = seq2seqModel.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T06:55:59.531321Z",
     "start_time": "2020-10-26T06:55:59.526907Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(seq2seqModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T17:26:34.323795Z",
     "start_time": "2020-10-26T17:26:34.311259Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(options, en_dict_size, cn_dict_size, device):\n",
    "    encoderModel = EncoderModel(en_dict_size=en_dict_size, \n",
    "                                dropout=options.dropout, \n",
    "                                enc_h_dim=options.hid_dim, \n",
    "                                embedding_dim=options.emb_dim, \n",
    "                                num_layers=options.n_layers)\n",
    "\n",
    "    decoderModel = DecoderModel(cn_dict_size=cn_dict_size, \n",
    "                                dropout=options.dropout, \n",
    "                                enc_h_dim=options.hid_dim, \n",
    "                                embedding_dim=options.emb_dim, \n",
    "                                num_layers=options.n_layers)\n",
    "\n",
    "    seq2seqModel = Seq2seqModel(encoderModel, decoderModel, device)\n",
    "    seq2seqModel = seq2seqModel.to(device)\n",
    "    return seq2seqModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T08:57:55.868281Z",
     "start_time": "2020-10-26T08:57:55.863285Z"
    }
   },
   "outputs": [],
   "source": [
    "# seq2seqModel = build_model(options, train_set.en_dict_size, train_set.cn_dict_size, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T06:55:59.609669Z",
     "start_time": "2020-10-26T06:55:59.532927Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(seq2seqModel.parameters(), lr=options.learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T06:55:59.669043Z",
     "start_time": "2020-10-26T06:55:59.612662Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss(ignore_index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train on batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T17:26:36.616627Z",
     "start_time": "2020-10-26T17:26:36.610580Z"
    }
   },
   "outputs": [],
   "source": [
    "def schedule_sampling(epoch):\n",
    "    # return f(epoch)\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T08:18:02.990502Z",
     "start_time": "2020-10-26T08:17:29.779044Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_loss = 0.0\n",
    "seq2seqModel.train()\n",
    "\n",
    "for i, x_y in enumerate(train_loader):\n",
    "    \n",
    "    x, y = x_y[0].to(device), x_y[1].to(device)\n",
    "    #print(i, x.shape)\n",
    "    \n",
    "    enc_input,  target = x, y\n",
    "    teacher_forcing_ratio = schedule_sampling()\n",
    "    dec_outputs, seq_outputs = seq2seqModel(enc_input, target, teacher_forcing_ratio)\n",
    "    # dec_outputs = (batch_size, seq_len, dict_size)\n",
    "    # seq_outputs = (batch_size, seq_len)\n",
    "    \n",
    "    dec_outputs = dec_outputs[:, 1:, :].reshape(-1, dec_outputs.shape[2]) # (batch_size, seq_len, dict_size) -> (batch_size*(seq_len-1), dict_size)\n",
    "    target = target[:, 1:].reshape(-1) # (batch_size, seq_len) -> (batch_size*(seq_len-1))\n",
    "    \n",
    "    batch_loss = loss_function(dec_outputs, target)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    batch_loss.backward()\n",
    "    grad_norm = torch.nn.utils.clip_grad_norm_(seq2seqModel.parameters(), 1) \n",
    "    optimizer.step()\n",
    "    \n",
    "    train_loss += batch_loss.item()\n",
    "    \n",
    "train_loss /= len(train_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T17:26:38.964266Z",
     "start_time": "2020-10-26T17:26:38.947531Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(seq2seqModel, train_loader, optimizer, loss_function, epoch, device):\n",
    "    train_loss = 0.0\n",
    "    seq2seqModel.train()\n",
    "    teacher_forcing_ratio = schedule_sampling(epoch)\n",
    "    \n",
    "    for i, x_y in enumerate(train_loader):\n",
    "\n",
    "        x, y = x_y[0].to(device), x_y[1].to(device)\n",
    "        #print(i, x.shape)\n",
    "\n",
    "        enc_input, target = x, y\n",
    "        dec_outputs, seq_outputs = seq2seqModel(enc_input, target, teacher_forcing_ratio)\n",
    "        # dec_outputs = (batch_size, seq_len, dict_size)\n",
    "        # seq_outputs = (batch_size, seq_len)\n",
    "\n",
    "        dec_outputs = dec_outputs[:, 1:, :].reshape(-1, dec_outputs.shape[2]) # (batch_size, seq_len, dict_size) -> (batch_size*(seq_len-1), dict_size)\n",
    "        target = target[:, 1:].reshape(-1) # (batch_size, seq_len) -> (batch_size*(seq_len-1))\n",
    "\n",
    "        batch_loss = loss_function(dec_outputs, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(seq2seqModel.parameters(), 1) \n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += batch_loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    return seq2seqModel, train_loss, optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## valid on batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T08:39:28.844069Z",
     "start_time": "2020-10-26T08:39:28.833532Z"
    }
   },
   "outputs": [],
   "source": [
    "for source, pred, target in zip([1,2,3], [4,5,6], [7,8,9]):\n",
    "    print(source, pred, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T08:46:19.790825Z",
     "start_time": "2020-10-26T08:46:19.100952Z"
    }
   },
   "outputs": [],
   "source": [
    "valid_loss = 0.0\n",
    "seq2seqModel.eval()\n",
    "\n",
    "results = []\n",
    "for i, x_y in enumerate(valid_loader):\n",
    "    \n",
    "    x, y = x_y[0].to(device), x_y[1].to(device)\n",
    "    #print(i, x.shape)\n",
    "    \n",
    "    enc_input,  target = x, y\n",
    "    dec_outputs, seq_outputs = seq2seqModel.inference(enc_input, target)\n",
    "    # dec_outputs = (batch_size, seq_len, dict_size)\n",
    "    # seq_outputs = (batch_size, seq_len)\n",
    "    \n",
    "    dec_outputs = dec_outputs[:, 1:, :].reshape(-1, dec_outputs.shape[2]) # (batch_size, seq_len, dict_size) -> (batch_size*(seq_len-1), dict_size)\n",
    "    target = target[:, 1:].reshape(-1) # (batch_size, seq_len) -> (batch_size*(seq_len-1))\n",
    "    \n",
    "    batch_loss = loss_function(dec_outputs, target)\n",
    "    \n",
    "    valid_loss += batch_loss.item()\n",
    "    \n",
    "    en_intSens, target_cn_intSens, predict_cn_intSens = x, y, seq_outputs\n",
    "    \n",
    "    en_strSens = intSens2strSens(en_intSens, valid_loader.dataset.int2word_en)\n",
    "    target_cn_strSens = intSens2strSens(target_cn_intSens, valid_loader.dataset.int2word_cn)\n",
    "    predict_cn_strSens = intSens2strSens(predict_cn_intSens, valid_loader.dataset.int2word_cn)\n",
    "    for en_strSen, target_cn_strSen, predict_cn_strSen in zip(en_strSens, target_cn_strSens, predict_cn_strSens):\n",
    "        results.append((en_strSen, target_cn_strSen, predict_cn_strSen))\n",
    "    \n",
    "    \n",
    "valid_loss /= len(valid_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T17:26:42.294490Z",
     "start_time": "2020-10-26T17:26:42.273600Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_model(seq2seqModel, valid_loader, loss_function, device):\n",
    "    valid_loss = 0.0\n",
    "    seq2seqModel.eval()\n",
    "\n",
    "    results = []\n",
    "    for i, x_y in enumerate(valid_loader):\n",
    "\n",
    "        x, y = x_y[0].to(device), x_y[1].to(device)\n",
    "        #print(i, x.shape)\n",
    "\n",
    "        enc_input, target = x, y\n",
    "        dec_outputs, seq_outputs = seq2seqModel.inference(enc_input, target)\n",
    "        # dec_outputs = (batch_size, seq_len, dict_size)\n",
    "        # seq_outputs = (batch_size, seq_len)\n",
    "\n",
    "        dec_outputs = dec_outputs[:, 1:, :].reshape(-1, dec_outputs.shape[2]) # (batch_size, seq_len, dict_size) -> (batch_size*(seq_len-1), dict_size)\n",
    "        target = target[:, 1:].reshape(-1) # (batch_size, seq_len) -> (batch_size*(seq_len-1))\n",
    "\n",
    "        batch_loss = loss_function(dec_outputs, target)\n",
    "\n",
    "        valid_loss += batch_loss.item()\n",
    "\n",
    "        en_intSens, target_cn_intSens, predict_cn_intSens = x, y[:, 1:], seq_outputs\n",
    "\n",
    "        en_strSens = intSens2strSens(en_intSens, valid_loader.dataset.int2word_en)\n",
    "        target_cn_strSens = intSens2strSens(target_cn_intSens, valid_loader.dataset.int2word_cn)\n",
    "        predict_cn_strSens = intSens2strSens(predict_cn_intSens, valid_loader.dataset.int2word_cn)\n",
    "        \n",
    "        for en_strSen, target_cn_strSen, predict_cn_strSen in zip(en_strSens, target_cn_strSens, predict_cn_strSens):\n",
    "            result = (en_strSen, target_cn_strSen, predict_cn_strSen)\n",
    "            results.append(result)\n",
    "\n",
    "    valid_loss /= len(valid_loader.dataset)\n",
    "    return valid_loss, results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train on epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T17:33:49.988392Z",
     "start_time": "2020-10-26T17:26:54.352539Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07993608517116971 0.10909937477111817\n",
      "0.06782084731260936 0.10667786693572998\n",
      "0.06375954887602064 0.09921484375\n",
      "0.06049883564313253 0.10013787269592285\n",
      "0.057725648562113444 0.09684638500213623\n"
     ]
    }
   ],
   "source": [
    "options = Options() \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "train_set = Seq2seqDataset(options.data_dir, \n",
    "                           which_dataset='training.txt', \n",
    "                           seq_len=options.seq_len)\n",
    "\n",
    "valid_set = Seq2seqDataset(options.data_dir, \n",
    "                           which_dataset='validation.txt', \n",
    "                           seq_len=options.seq_len)\n",
    "\n",
    "train_loader = data.DataLoader(train_set, batch_size=options.batch_size, shuffle=True)\n",
    "valid_loader = data.DataLoader(valid_set, batch_size=options.batch_size, shuffle=False)\n",
    "\n",
    "seq2seqModel = build_model(options, train_set.en_dict_size, train_set.cn_dict_size, device)\n",
    "optimizer = torch.optim.Adam(seq2seqModel.parameters(), lr=options.learning_rate)\n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "for epoch in range(5):\n",
    "    # train\n",
    "    seq2seqModel, train_loss, optimizer = train_model(seq2seqModel, \n",
    "                                                      train_loader, \n",
    "                                                      optimizer, \n",
    "                                                      loss_function, \n",
    "                                                      epoch, \n",
    "                                                      device)\n",
    "    # valid\n",
    "    valid_loss, results = test_model(seq2seqModel, \n",
    "                                     valid_loader, \n",
    "                                     loss_function, \n",
    "                                     device)\n",
    "    print(train_loss, valid_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T16:03:43.444440Z",
     "start_time": "2020-10-26T16:03:43.438449Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loss, valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T16:04:28.905333Z",
     "start_time": "2020-10-26T16:04:28.897098Z"
    }
   },
   "outputs": [],
   "source": [
    "results[38]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
