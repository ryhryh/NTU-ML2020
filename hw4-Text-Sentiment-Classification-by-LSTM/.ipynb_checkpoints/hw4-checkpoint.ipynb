{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:09:24.267926Z",
     "start_time": "2020-06-03T06:09:23.548522Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "# import torch.nn.functional as F\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='2' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:09:24.274523Z",
     "start_time": "2020-06-03T06:09:24.271042Z"
    }
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "def get_parms(f):\n",
    "    return inspect.signature(f).parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:09:26.167536Z",
     "start_time": "2020-06-03T06:09:24.279371Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_label = pd.read_csv(\n",
    "    './datasets/training_label.txt', sep='\\n', names=['raw'])[:] ###\n",
    "training_nolabel = pd.read_csv(\n",
    "    './datasets/training_nolabel.txt', sep='\\n', names=['raw'])[:] ###\n",
    "testing_data = pd.read_csv(\n",
    "    './datasets/testing_data.txt', sep='\\n', names=['raw'])[:] ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:09:26.198188Z",
     "start_time": "2020-06-03T06:09:26.169814Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 +++$+++ are wtf ... awww thanks !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 +++$+++ leavingg to wait for kaysie to arriv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 raw\n",
       "0                1 +++$+++ are wtf ... awww thanks !\n",
       "1  1 +++$+++ leavingg to wait for kaysie to arriv..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mkhang mlbo . dami niang followers ee . di q r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>don ' t you hate it when you hang on to a seem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 raw\n",
       "0  mkhang mlbo . dami niang followers ee . di q r...\n",
       "1  don ' t you hate it when you hang on to a seem..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id,text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0,my dog ate our dinner . no , seriously ... h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 raw\n",
       "0                                            id,text\n",
       "1  0,my dog ate our dinner . no , seriously ... h..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(training_label.head(2))\n",
    "display(training_nolabel.head(2))\n",
    "display(testing_data.head(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## text, label, split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:09:27.041484Z",
     "start_time": "2020-06-03T06:09:26.199608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 +++$+++ are wtf ... awww thanks !</td>\n",
       "      <td>1</td>\n",
       "      <td>are wtf ... awww thanks !</td>\n",
       "      <td>[are, wtf, ..., awww, thanks, !]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   raw  label                       text  \\\n",
       "0  1 +++$+++ are wtf ... awww thanks !      1  are wtf ... awww thanks !   \n",
       "\n",
       "                         text_split  \n",
       "0  [are, wtf, ..., awww, thanks, !]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_label['label'] = training_label.raw.apply(lambda x: int(x.split(' +++$+++ ')[0]))\n",
    "training_label['text'] = training_label.raw.apply(lambda x: x.split(' +++$+++ ')[1])\n",
    "training_label['text_split'] = training_label.text.apply(lambda x: x.split(' '))\n",
    "\n",
    "training_label.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:09:30.676127Z",
     "start_time": "2020-06-03T06:09:27.043099Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw</th>\n",
       "      <th>text</th>\n",
       "      <th>text_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mkhang mlbo . dami niang followers ee . di q r...</td>\n",
       "      <td>mkhang mlbo . dami niang followers ee . di q r...</td>\n",
       "      <td>[mkhang, mlbo, ., dami, niang, followers, ee, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 raw  \\\n",
       "0  mkhang mlbo . dami niang followers ee . di q r...   \n",
       "\n",
       "                                                text  \\\n",
       "0  mkhang mlbo . dami niang followers ee . di q r...   \n",
       "\n",
       "                                          text_split  \n",
       "0  [mkhang, mlbo, ., dami, niang, followers, ee, ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_nolabel['text'] = training_nolabel['raw']\n",
    "training_nolabel['text_split'] = training_nolabel.text.apply(lambda x: x.split(' '))\n",
    "\n",
    "training_nolabel.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:09:31.212870Z",
     "start_time": "2020-06-03T06:09:30.677635Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0,my dog ate our dinner . no , seriously ... h...</td>\n",
       "      <td>0</td>\n",
       "      <td>my dog ate our dinner . no</td>\n",
       "      <td>[my, dog, ate, our, dinner, ., no, ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 raw id  \\\n",
       "0  0,my dog ate our dinner . no , seriously ... h...  0   \n",
       "\n",
       "                          text                            text_split  \n",
       "0  my dog ate our dinner . no   [my, dog, ate, our, dinner, ., no, ]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data['id'] = testing_data.raw.apply(lambda x: x.split(',')[0])\n",
    "testing_data['text'] = testing_data.raw.apply(lambda x: x.split(',')[1])\n",
    "testing_data = testing_data.drop([0], inplace=False).reset_index(drop=True) ###\n",
    "testing_data['text_split'] = testing_data.text.apply(lambda x: x.split(' '))\n",
    "\n",
    "testing_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train word2vec\n",
    "https://www.kaggle.com/jerrykuo7727/word2vec\n",
    "\n",
    "https://radimrehurek.com/gensim/models/word2vec.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:09:31.225893Z",
     "start_time": "2020-06-03T06:09:31.214286Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['are', 'wtf', '...', 'awww', 'thanks', '!']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences = training_label.text_split.tolist()\n",
    "test_sentences = testing_data.text_split.tolist()\n",
    "train_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:09:31.332696Z",
     "start_time": "2020-06-03T06:09:31.228907Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['are', 'wtf', '...', 'awww', 'thanks', '!']\n",
      "['is', 'a', 'bit', 'concerned', 'that', 'his', 'wolves', 'flag', 'might', 'fly', 'away']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_sentences = train_sentences + test_sentences\n",
    "\n",
    "print(train_test_sentences[0])\n",
    "np.random.shuffle(train_test_sentences)\n",
    "print(train_test_sentences[0])\n",
    "\n",
    "len(train_test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:09:32.479069Z",
     "start_time": "2020-06-03T06:09:31.334606Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "# vars(Word2Vec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:10:53.068033Z",
     "start_time": "2020-06-03T06:09:32.481238Z"
    }
   },
   "outputs": [],
   "source": [
    "# sg=skip-gram, sg=0 => cbow\n",
    "embedding_dim = 250 \n",
    "w2v_model = Word2Vec(\n",
    "    train_test_sentences, size=embedding_dim, window=5, min_count=2, workers=12, iter=10, sg=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:10:53.922582Z",
     "start_time": "2020-06-03T06:10:53.073967Z"
    }
   },
   "outputs": [],
   "source": [
    "w2v_model.save('w2v.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:10:53.927472Z",
     "start_time": "2020-06-03T06:10:53.925009Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# torch.empty(1, 10).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:10:53.998625Z",
     "start_time": "2020-06-03T06:10:53.928901Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get_parms(model_word2vec.wv.most_similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:10:54.048854Z",
     "start_time": "2020-06-03T06:10:54.002847Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model_word2vec.wv['this'].shape\n",
    "# model_word2vec.wv.vocab\n",
    "# model_word2vec.wv.most_similar('and', topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:10:54.359975Z",
     "start_time": "2020-06-03T06:10:54.052819Z"
    }
   },
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec.load('w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:10:54.403851Z",
     "start_time": "2020-06-03T06:10:54.362074Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48098\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48093</th>\n",
       "      <td>morroc</td>\n",
       "      <td>48093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48094</th>\n",
       "      <td>linely</td>\n",
       "      <td>48094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48095</th>\n",
       "      <td>mori</td>\n",
       "      <td>48095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48096</th>\n",
       "      <td>&lt;PAD&gt;</td>\n",
       "      <td>48096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48097</th>\n",
       "      <td>&lt;UNK&gt;</td>\n",
       "      <td>48097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  index\n",
       "48093  morroc  48093\n",
       "48094  linely  48094\n",
       "48095    mori  48095\n",
       "48096   <PAD>  48096\n",
       "48097   <UNK>  48097"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['morroc', 'linely', 'mori', '<PAD>', '<UNK>']\n"
     ]
    }
   ],
   "source": [
    "all_words = list(w2v_model.wv.vocab.keys())+['<PAD>', '<UNK>'] # UNK = unknown\n",
    "print(len(all_words))\n",
    "\n",
    "df_word = pd.DataFrame()\n",
    "df_word['word'] = all_words\n",
    "df_word['index'] = df_word.index\n",
    "display(df_word[-5:])\n",
    "\n",
    "word2idx = dict(zip(df_word.word, df_word.index))\n",
    "idx2word = df_word.word.tolist()\n",
    "print(idx2word[-5:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:10:55.208136Z",
     "start_time": "2020-06-03T06:10:54.405501Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48098, 250])\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = torch.empty(len(idx2word), embedding_dim) ###\n",
    "\n",
    "for i in range(len(df_word)-2): # exclude <PAD>, <UNK>\n",
    "    word = idx2word[i]\n",
    "    embedding_matrix[i] = torch.tensor(w2v_model.wv[word])\n",
    "\n",
    "print(embedding_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:10:55.212568Z",
     "start_time": "2020-06-03T06:10:55.209714Z"
    }
   },
   "outputs": [],
   "source": [
    "# [x if x==1 else 0 for x in [1,2,3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:10:55.257083Z",
     "start_time": "2020-06-03T06:10:55.214095Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(type(embedding_matrix))\n",
    "# embedding_matrix = torch.tensor(embedding_matrix)\n",
    "# print(type(embedding_matrix))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pad sequence\n",
    "https://github.com/keras-team/keras-preprocessing/blob/master/keras_preprocessing/sequence.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:10:55.310014Z",
     "start_time": "2020-06-03T06:10:55.261040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 48096, 48096]\n",
      "[1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "def pad_sequence(sequence, sequence_len):\n",
    "    pad_len = sequence_len - len(sequence) \n",
    "    if pad_len > 0:\n",
    "        paddings = [word2idx['<PAD>']] * pad_len\n",
    "        sequence = sequence + paddings # post padding\n",
    "    sequence = sequence[:sequence_len]\n",
    "    return sequence\n",
    "        \n",
    "print(pad_sequence([1,2,3], 5))   \n",
    "print(pad_sequence([1,2,3,4,5,6,7,8], 5))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sentence word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:10:55.362461Z",
     "start_time": "2020-06-03T06:10:55.314261Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[58, 4, 10030, 5884, 48096, 48096]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sentence_word2idx(sentence_word, sequence_len):\n",
    "    sentence_idx = []\n",
    "    for word in sentence_word:\n",
    "        idx = word2idx[word] if word in word2idx else word2idx['<UNK>']\n",
    "        sentence_idx.append(idx)\n",
    "    sentence_idx = pad_sequence(sentence_idx, sequence_len)\n",
    "    return sentence_idx\n",
    "    \n",
    "sentence_word2idx(['of', 'that', 'gona', 'nba'], 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X_train, Y_train, X_valid, Y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:10:57.526518Z",
     "start_time": "2020-06-03T06:10:55.366198Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 717, 11, 249, 445, 26, 256, 28137, 471, 175, 935, 13, 48097, 27356, 19, 48096, 48096, 48096, 48096, 48096] 0\n"
     ]
    }
   ],
   "source": [
    "train_sentences = training_label.text_split.tolist()\n",
    "train_labels = training_label.label.tolist()\n",
    "\n",
    "\n",
    "sequence_len = 20\n",
    "train_sentences = [sentence_word2idx(sentence, sequence_len) for sentence in train_sentences]\n",
    "train_sentences = [pad_sequence(sentence, sequence_len) for sentence in train_sentences]\n",
    "\n",
    "print(train_sentences[2], train_labels[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:10:58.554919Z",
     "start_time": "2020-06-03T06:10:57.528398Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[253, 1248, 140, 460, 102, 1387, 45, 140, 253, 38, 48096, 48096, 48096, 48096, 48096, 48096, 48096, 48096, 48096, 48096]\n"
     ]
    }
   ],
   "source": [
    "test_sentences = testing_data.text_split.tolist()\n",
    "\n",
    "\n",
    "sequence_len = 20\n",
    "test_sentences = [sentence_word2idx(sentence, sequence_len) for sentence in test_sentences]\n",
    "test_sentences = [pad_sequence(sentence, sequence_len) for sentence in test_sentences]\n",
    "\n",
    "print(test_sentences[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:10:58.594546Z",
     "start_time": "2020-06-03T06:10:58.556673Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:10:58.701627Z",
     "start_time": "2020-06-03T06:10:58.596332Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160000 40000\n",
      "[9228, 96, 187, 35230, 19, 11, 102, 408, 44, 2813, 29, 376, 58, 4472, 4473, 48096, 48096, 48096, 48096, 48096] 0\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, Y_train, Y_valid = train_test_split(train_sentences, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(len(X_train), len(X_valid))\n",
    "print(X_train[2], Y_train[2])\n",
    "print(type(X_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:10:58.709777Z",
     "start_time": "2020-06-03T06:10:58.706230Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[253, 1248, 140, 460, 102, 1387, 45, 140, 253, 38, 48096, 48096, 48096, 48096, 48096, 48096, 48096, 48096, 48096, 48096]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "X_test = test_sentences\n",
    "print(X_test[2])\n",
    "print(type(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:10:58.771714Z",
     "start_time": "2020-06-03T06:10:58.711631Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:10:58.825056Z",
     "start_time": "2020-06-03T06:10:58.775740Z"
    }
   },
   "outputs": [],
   "source": [
    "class TwitterDataset(Dataset):\n",
    "    def __init__(self, X, Y=None):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if self.Y == None: return np.array(self.X[idx])\n",
    "        return np.array(self.X[idx]), np.array(self.Y[idx])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:10:58.874375Z",
     "start_time": "2020-06-03T06:10:58.828984Z"
    }
   },
   "outputs": [],
   "source": [
    "train_set = TwitterDataset(X_train, Y_train)\n",
    "valid_set = TwitterDataset(X_valid, Y_valid)\n",
    "test_set = TwitterDataset(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:10:58.923662Z",
     "start_time": "2020-06-03T06:10:58.878372Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:10:58.975099Z",
     "start_time": "2020-06-03T06:10:58.927688Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 128 ###\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True) ###\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:10:59.057495Z",
     "start_time": "2020-06-03T06:10:58.979099Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([128, 20]) torch.Size([128])\n",
      "tensor([  31, 3272, 1048,   43,  325,  147,   38, 1504,   26,   32,  225, 1541,\n",
      "         228,  499,   94,  228,  498,  203,   58,  241]) tensor(0)\n"
     ]
    }
   ],
   "source": [
    "g = iter(train_loader)\n",
    "x_batch, y_batch = next(g)\n",
    "\n",
    "print(type(x_batch))\n",
    "print(x_batch.shape, y_batch.shape)\n",
    "print(x_batch[0], y_batch[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:10:59.077530Z",
     "start_time": "2020-06-03T06:10:59.059320Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([128, 20])\n",
      "tensor([   41,  1924,  1520,   527,   209,    19,   191,    28, 48096, 48096,\n",
      "        48096, 48096, 48096, 48096, 48096, 48096, 48096, 48096, 48096, 48096])\n"
     ]
    }
   ],
   "source": [
    "g = iter(test_loader)\n",
    "x_batch = next(g)\n",
    "\n",
    "print(type(x_batch))\n",
    "print(x_batch.shape)\n",
    "print(x_batch[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T07:53:50.524354Z",
     "start_time": "2020-06-02T07:53:50.517545Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:10:59.124693Z",
     "start_time": "2020-06-03T06:10:59.079570Z"
    }
   },
   "outputs": [],
   "source": [
    "class Option:\n",
    "    def __init__(self, embedding_matrix=None, hidden_dim=None, num_layers=None, dropout=0.5, embedding_requires_grad=False):\n",
    "        self.embedding_matrix = embedding_matrix\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.embedding_requires_grad = embedding_requires_grad\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model\n",
    "- https://pytorch.org/docs/master/generated/torch.nn.LSTM.html?highlight=nn%20lstm#torch.nn.LSTM\n",
    "- https://pytorch.org/docs/master/generated/torch.nn.Sequential.html?highlight=nn%20sequential#torch.nn.Sequential\n",
    "- https://pytorch.org/docs/master/generated/torch.nn.Embedding.html?highlight=nn%20embedding#torch.nn.Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:10:59.174263Z",
     "start_time": "2020-06-03T06:10:59.128616Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:10:59.224872Z",
     "start_time": "2020-06-03T06:10:59.178315Z"
    }
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, opt):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.opt = opt\n",
    "        self.num_embeddings = self.opt.embedding_matrix.shape[0]\n",
    "        self.embedding_dim = self.opt.embedding_matrix.shape[1]\n",
    "        self.setup_embedding()\n",
    "        self.setup_lstm()\n",
    "        self.setup_fcn()\n",
    "        \n",
    "    def setup_embedding(self):\n",
    "        self.embedding = nn.Embedding(self.num_embeddings, self.embedding_dim)\n",
    "        self.embedding.weight = nn.Parameter(self.opt.embedding_matrix) ###\n",
    "        self.embedding.weight.requires_grad = self.opt.embedding_requires_grad\n",
    "        \n",
    "    def setup_lstm(self):\n",
    "        self.lstm = nn.LSTM(input_size=self.embedding_dim, \n",
    "                            hidden_size=self.opt.hidden_dim, \n",
    "                            num_layers=self.opt.num_layers, \n",
    "                            batch_first=True)\n",
    "        \n",
    "    def setup_fcn(self):\n",
    "        self.fcn = nn.Sequential(nn.Dropout(self.opt.dropout),\n",
    "                                 nn.Linear(self.opt.hidden_dim, 1),\n",
    "                                 nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, input):\n",
    "        embeds = self.embedding(input)\n",
    "        lstm_output, (h, c) = self.lstm(embeds, (None)) ###\n",
    "        lstm_last_ts = lstm_output[:, -1, :] # (batch, seq, feature)\n",
    "        fcn_output = self.fcn(lstm_last_ts)\n",
    "        \n",
    "#         print('input.shape', input.shape)\n",
    "#         print('embeds.shape', embeds.shape)\n",
    "#         print('lstm_output.shape', lstm_output.shape)\n",
    "#         print('lstm_last_ts.shape', lstm_last_ts.shape)\n",
    "#         print('fcn_output.shape', fcn_output.shape)\n",
    "        \n",
    "        return fcn_output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T17:28:36.153514Z",
     "start_time": "2020-06-02T17:28:36.123579Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:10:59.288971Z",
     "start_time": "2020-06-03T06:10:59.227616Z"
    }
   },
   "outputs": [],
   "source": [
    "# input_size=10\n",
    "# hidden_size=20\n",
    "# num_layers=10\n",
    "\n",
    "# batch_size = 7\n",
    "# ts_size = 5\n",
    "\n",
    "# rnn = nn.LSTM(input_size, hidden_size, num_layers)\n",
    "# input = torch.randn(batch_size, ts_size, input_size)\n",
    "# h0 = torch.randn(num_layers, ts_size, hidden_size)\n",
    "# c0 = torch.randn(num_layers, ts_size, hidden_size)\n",
    "# output, (hn, cn) = rnn(input, (h0, c0))\n",
    "\n",
    "# print(h0.shape, c0.shape)\n",
    "# print(output.shape, hn.shape, cn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:10:59.355505Z",
     "start_time": "2020-06-03T06:10:59.292752Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# opt = Option(embedding_matrix=embedding_matrix, \n",
    "#              hidden_dim=150, \n",
    "#              num_layers=1, \n",
    "#              dropout=0.5, \n",
    "#              embedding_requires_grad=False)\n",
    "\n",
    "# model = Classifier(opt).cuda()\n",
    "# inputs = np.array([[1,2,3], [4,5,6]])\n",
    "# inputs = torch.tensor(inputs).cuda()\n",
    "\n",
    "# model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:10:59.407640Z",
     "start_time": "2020-06-03T06:10:59.359429Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:26:32.094050Z",
     "start_time": "2020-06-03T06:26:32.076849Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2 0.5 0.9]\n",
      "[0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "def y2label(y):\n",
    "    y[y>=0.5] = 1\n",
    "    y[y<0.5] = 0\n",
    "    return y\n",
    "    \n",
    "d = np.array([0.2, 0.5, 0.9])\n",
    "print(d)\n",
    "d = y2label(d)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:10:59.462479Z",
     "start_time": "2020-06-03T06:10:59.411659Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_match_num(y_hat, y):\n",
    "    y_hat[y_hat>=0.5] = 1\n",
    "    y_hat[y_hat<0.5] = 0\n",
    "    match = (y_hat==y)\n",
    "    match_num = sum(match)\n",
    "#     print(match, y_hat, y)\n",
    "    return match_num\n",
    "    \n",
    "get_match_num(np.array([0.2, 0.5, 0.9]), np.array([0, 0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:10:59.509617Z",
     "start_time": "2020-06-03T06:10:59.465958Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([48098, 250])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:10:59.557747Z",
     "start_time": "2020-06-03T06:10:59.513251Z"
    }
   },
   "outputs": [],
   "source": [
    "opt = Option(embedding_matrix=embedding_matrix, \n",
    "             hidden_dim=150, \n",
    "             num_layers=1, \n",
    "             dropout=0.5, \n",
    "             embedding_requires_grad=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:11:03.833402Z",
     "start_time": "2020-06-03T06:10:59.561713Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Classifier(opt).cuda()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), \n",
    "                       lr=0.001)\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "# history\n",
    "df_history = pd.DataFrame({'epoch':[0],'time':[0],'train_loss':[float('inf')],'train_acc':[0],'valid_loss':[float('inf')],'valid_acc':[0]})\n",
    "\n",
    "# early stop\n",
    "monitor = 'valid_acc'\n",
    "min_delta = 0.01\n",
    "patience = 5\n",
    "best_monitor = df_history.loc[0,monitor]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:13:24.046205Z",
     "start_time": "2020-06-03T06:11:03.835927Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "epoch = 1, time = 14, train_loss = 0.0039, train_acc = 0.7575, valid_loss = 0.0036, valid_acc = 0.7846\n",
      "valid_acc improve from 0.0000 to 0.7846, saving model\n",
      "--------------------------------------------------------------------------------\n",
      "epoch = 2, time = 14, train_loss = 0.0035, train_acc = 0.7877, valid_loss = 0.0034, valid_acc = 0.7954\n",
      "valid_acc improve from 0.7846 to 0.7954, saving model\n",
      "--------------------------------------------------------------------------------\n",
      "epoch = 3, time = 7, train_loss = 0.0034, train_acc = 0.7977, valid_loss = 0.0034, valid_acc = 0.8011\n",
      "--------------------------------------------------------------------------------\n",
      "epoch = 4, time = 6, train_loss = 0.0033, train_acc = 0.8060, valid_loss = 0.0033, valid_acc = 0.8051\n",
      "--------------------------------------------------------------------------------\n",
      "epoch = 5, time = 17, train_loss = 0.0032, train_acc = 0.8135, valid_loss = 0.0032, valid_acc = 0.8100\n",
      "valid_acc improve from 0.7954 to 0.8100, saving model\n",
      "--------------------------------------------------------------------------------\n",
      "epoch = 6, time = 17, train_loss = 0.0031, train_acc = 0.8198, valid_loss = 0.0032, valid_acc = 0.8102\n",
      "--------------------------------------------------------------------------------\n",
      "epoch = 7, time = 9, train_loss = 0.0030, train_acc = 0.8263, valid_loss = 0.0033, valid_acc = 0.8096\n",
      "--------------------------------------------------------------------------------\n",
      "epoch = 8, time = 7, train_loss = 0.0029, train_acc = 0.8335, valid_loss = 0.0033, valid_acc = 0.8106\n",
      "--------------------------------------------------------------------------------\n",
      "epoch = 9, time = 15, train_loss = 0.0028, train_acc = 0.8409, valid_loss = 0.0033, valid_acc = 0.8074\n",
      "--------------------------------------------------------------------------------\n",
      "epoch = 10, time = 14, train_loss = 0.0027, train_acc = 0.8479, valid_loss = 0.0034, valid_acc = 0.8044\n",
      "--------------------------------------------------------------------------------\n",
      "epoch = 11, time = 15, train_loss = 0.0025, train_acc = 0.8566, valid_loss = 0.0036, valid_acc = 0.8074\n",
      "early stop\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print('-'*80)\n",
    "    epoch_start_time = time.time()\n",
    "    train_acc = 0.\n",
    "    valid_acc = 0.\n",
    "    train_loss = 0.\n",
    "    valid_loss = 0.\n",
    "    \n",
    "    # train\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        x, y = data[0].cuda(), data[1].cuda()\n",
    "        y = y.float() ### y and y_hat need to be the same dtype\n",
    "        \n",
    "        optimizer.zero_grad() # gradient accumulate, need to reset # ex: adagrad\n",
    "        y_hat = model(x)\n",
    "        y_hat = y_hat.reshape(-1) ### align with y for calculate batch_loss\n",
    "        #print(y_hat.shape, y.shape)\n",
    "        batch_loss = criterion(y_hat, y)\n",
    "        batch_loss.backward() \n",
    "        optimizer.step() \n",
    "        \n",
    "        train_loss += batch_loss.item()\n",
    "        \n",
    "        label_hat = y_hat.cpu().data.numpy()\n",
    "        label = y.cpu().data.numpy()\n",
    "        #label_hat = label_hat.reshape(-1) ###\n",
    "        match_num = get_match_num(label_hat, label)\n",
    "        train_acc += match_num\n",
    "    \n",
    "    # valid\n",
    "    model.eval()\n",
    "    for i, data in enumerate(valid_loader):\n",
    "        x, y = data[0].cuda(), data[1].cuda()\n",
    "        y = y.float() ###\n",
    "        \n",
    "        y_hat = model(x)\n",
    "        y_hat = y_hat.reshape(-1) ### align with y for calculate batch_loss\n",
    "        batch_loss = criterion(y_hat, y)\n",
    "        \n",
    "        valid_loss += batch_loss.item()\n",
    "        \n",
    "        label_hat = y_hat.cpu().data.numpy()\n",
    "        label = y.cpu().data.numpy()\n",
    "        #label_hat = label_hat.reshape(-1) ###\n",
    "        match_num = get_match_num(label_hat, label)\n",
    "        valid_acc += match_num\n",
    "        \n",
    "    # progress bar\n",
    "    epoch += 1\n",
    "    t = time.time() - epoch_start_time\n",
    "    \n",
    "    train_loss /= len(train_set)\n",
    "    train_acc /= len(train_set)\n",
    "    \n",
    "    valid_loss /= len(valid_set)\n",
    "    valid_acc /= len(valid_set)\n",
    "    \n",
    "    print('epoch = %d, time = %d, train_loss = %.4f, train_acc = %.4f, valid_loss = %.4f, valid_acc = %.4f'%(\n",
    "        epoch, t, train_loss, train_acc, valid_loss, valid_acc))\n",
    "    \n",
    "    # history\n",
    "    df_history_epoch = pd.DataFrame({'epoch':[epoch],'time':[t],'train_loss':[train_loss],'train_acc':[train_acc],'valid_loss':[valid_loss],'valid_acc':[valid_acc]})\n",
    "    df_history = df_history.append(df_history_epoch)\n",
    "    \n",
    "    # checkpointer\n",
    "    monitor_list = df_history[monitor].tolist()\n",
    "    cur_monitor = monitor_list[-1]\n",
    "    if cur_monitor-best_monitor > min_delta:\n",
    "        torch.save(model.state_dict(), './best_model.pt')\n",
    "        print('%s improve from %.4f to %.4f, saving model'%(monitor, best_monitor, cur_monitor))\n",
    "        \n",
    "        best_monitor = cur_monitor\n",
    "        i_best_monitor = epoch\n",
    "    \n",
    "    # earlystop\n",
    "    i_cur_monitor = epoch\n",
    "    if (i_cur_monitor-i_best_monitor) > patience: \n",
    "        print('early stop')\n",
    "        break\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:13:24.060968Z",
     "start_time": "2020-06-03T06:13:24.048366Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>time</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>14.915117</td>\n",
       "      <td>0.003864</td>\n",
       "      <td>0.757550</td>\n",
       "      <td>0.003585</td>\n",
       "      <td>0.784600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>14.448015</td>\n",
       "      <td>0.003523</td>\n",
       "      <td>0.787744</td>\n",
       "      <td>0.003423</td>\n",
       "      <td>0.795350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7.086141</td>\n",
       "      <td>0.003383</td>\n",
       "      <td>0.797687</td>\n",
       "      <td>0.003361</td>\n",
       "      <td>0.801075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6.993994</td>\n",
       "      <td>0.003275</td>\n",
       "      <td>0.805987</td>\n",
       "      <td>0.003303</td>\n",
       "      <td>0.805100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>17.323967</td>\n",
       "      <td>0.003180</td>\n",
       "      <td>0.813488</td>\n",
       "      <td>0.003244</td>\n",
       "      <td>0.809975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>17.317762</td>\n",
       "      <td>0.003094</td>\n",
       "      <td>0.819800</td>\n",
       "      <td>0.003244</td>\n",
       "      <td>0.810175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>9.022784</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.826294</td>\n",
       "      <td>0.003299</td>\n",
       "      <td>0.809575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>7.039088</td>\n",
       "      <td>0.002903</td>\n",
       "      <td>0.833462</td>\n",
       "      <td>0.003293</td>\n",
       "      <td>0.810650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>15.133307</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>0.840894</td>\n",
       "      <td>0.003313</td>\n",
       "      <td>0.807400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>14.862788</td>\n",
       "      <td>0.002672</td>\n",
       "      <td>0.847875</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.804425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>15.024065</td>\n",
       "      <td>0.002543</td>\n",
       "      <td>0.856581</td>\n",
       "      <td>0.003555</td>\n",
       "      <td>0.807425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch       time  train_loss  train_acc  valid_loss  valid_acc\n",
       "0       0   0.000000         inf   0.000000         inf   0.000000\n",
       "1       1  14.915117    0.003864   0.757550    0.003585   0.784600\n",
       "2       2  14.448015    0.003523   0.787744    0.003423   0.795350\n",
       "3       3   7.086141    0.003383   0.797687    0.003361   0.801075\n",
       "4       4   6.993994    0.003275   0.805987    0.003303   0.805100\n",
       "5       5  17.323967    0.003180   0.813488    0.003244   0.809975\n",
       "6       6  17.317762    0.003094   0.819800    0.003244   0.810175\n",
       "7       7   9.022784    0.002996   0.826294    0.003299   0.809575\n",
       "8       8   7.039088    0.002903   0.833462    0.003293   0.810650\n",
       "9       9  15.133307    0.002790   0.840894    0.003313   0.807400\n",
       "10     10  14.862788    0.002672   0.847875    0.003400   0.804425\n",
       "11     11  15.024065    0.002543   0.856581    0.003555   0.807425"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_history = df_history.reset_index(drop=True)\n",
    "df_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:15:47.148820Z",
     "start_time": "2020-06-03T06:15:47.143836Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_history.plot(y=['train_loss', 'valid_loss'])\n",
    "# df_history.plot(y=['train_acc', 'valid_acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:13:24.193830Z",
     "start_time": "2020-06-03T06:13:24.148007Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# model\n",
    "# loss\n",
    "# optimizer\n",
    "# epochs\n",
    "    # initialize time\n",
    "    # initialize metric\n",
    "\n",
    "    # model.train()\n",
    "    # batchs\n",
    "        # reset gradient !!!\n",
    "        # y_hat\n",
    "        # batch_loss\n",
    "        # gradient\n",
    "        # update\n",
    "        # metric\n",
    "    \n",
    "    # model.eval()\n",
    "    # batchs\n",
    "        # y_hat\n",
    "        # batch_loss\n",
    "        # metric\n",
    "        \n",
    "    # progress bar\n",
    "        # epoch time\n",
    "        # train_loss, valid_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:13:24.243724Z",
     "start_time": "2020-06-03T06:13:24.197927Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# d = np.array([0.3,0.5,0.8])\n",
    "# d[d>=0.5] = 1\n",
    "# d[d<0.5] = 0\n",
    "# d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:43:37.723730Z",
     "start_time": "2020-06-03T06:43:34.947165Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_label_hat = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader):\n",
    "        x = data.cuda() ###\n",
    "\n",
    "        y_hat = model(x)\n",
    "        y_hat = y_hat.reshape(-1) ### align with y for calculate batch_loss\n",
    "        \n",
    "        y_hat = y_hat.cpu().data.numpy()\n",
    "        label_hat = y2label(y_hat).tolist()\n",
    "        test_label_hat += label_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:43:37.729711Z",
     "start_time": "2020-06-03T06:43:37.725522Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_label_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
