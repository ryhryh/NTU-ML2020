{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ipmort "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T12:36:10.823665Z",
     "start_time": "2020-11-01T12:36:09.882105Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T12:36:12.859274Z",
     "start_time": "2020-11-01T12:36:12.847688Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(image_list):\n",
    "    \"\"\" Normalize Image and Permute (N,H,W,C) to (N,C,H,W)\n",
    "    Args:\n",
    "      image_list: List of images (9000, 32, 32, 3)\n",
    "    Returns:\n",
    "      image_list: List of images (9000, 3, 32, 32)\n",
    "    \"\"\"\n",
    "    image_list = np.array(image_list)\n",
    "    image_list = np.transpose(image_list, (0, 3, 1, 2))\n",
    "    image_list = (image_list / 255.0) * 2 - 1\n",
    "    image_list = image_list.astype(np.float32)\n",
    "    return image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T12:36:15.943550Z",
     "start_time": "2020-11-01T12:36:15.925253Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def count_parameters(model, only_trainable=False):\n",
    "    if only_trainable:\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    else:\n",
    "        return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "def same_seeds(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    np.random.seed(seed)  # Numpy module.\n",
    "    random.seed(seed)  # Python random module.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T12:58:08.076895Z",
     "start_time": "2020-11-01T12:58:08.066453Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_model(model, file_name):\n",
    "    file_path = os.path.join('..', 'checkpoints', file_name)\n",
    "    torch.save(model.state_dict(), file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T11:50:50.919907Z",
     "start_time": "2020-11-01T11:50:50.863280Z"
    }
   },
   "outputs": [],
   "source": [
    "trainX = np.load(os.path.join('..', 'datasets', 'trainX.npy'))\n",
    "trainX.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T11:51:12.399557Z",
     "start_time": "2020-11-01T11:51:12.389993Z"
    }
   },
   "outputs": [],
   "source": [
    "valX = np.load(os.path.join('..', 'datasets', 'valX.npy'))\n",
    "valX.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T11:51:28.939309Z",
     "start_time": "2020-11-01T11:51:28.931886Z"
    }
   },
   "outputs": [],
   "source": [
    "valY = np.load(os.path.join('..', 'datasets', 'valY.npy'))\n",
    "valY.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T12:36:17.564886Z",
     "start_time": "2020-11-01T12:36:17.551148Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, file_name):\n",
    "        self.file_name = file_name\n",
    "        self.setup()\n",
    "        \n",
    "    def setup(self):\n",
    "        self.data = np.load(os.path.join('..', 'datasets', self.file_name))\n",
    "        self.data = preprocess(self.data)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.data[idx]\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T12:16:02.413570Z",
     "start_time": "2020-11-01T12:16:02.037072Z"
    }
   },
   "outputs": [],
   "source": [
    "imageDataset = ImageDataset('trainX.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T12:16:04.967455Z",
     "start_time": "2020-11-01T12:16:04.957201Z"
    }
   },
   "outputs": [],
   "source": [
    "imageDataset[10].shape, len(imageDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T12:17:22.974792Z",
     "start_time": "2020-11-01T12:17:22.968453Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(imageDataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T12:18:16.023181Z",
     "start_time": "2020-11-01T12:18:15.830927Z"
    }
   },
   "outputs": [],
   "source": [
    "a = next(iter(train_loader))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T12:36:21.885570Z",
     "start_time": "2020-11-01T12:36:21.866403Z"
    }
   },
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(128, 256, 3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    " \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, 5, stride=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 64, 9, stride=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 3, 17, stride=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        code = self.encoder(x)\n",
    "        x_hat  = self.decoder(code)\n",
    "        return code, x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T12:24:21.401105Z",
     "start_time": "2020-11-01T12:24:21.363093Z"
    }
   },
   "outputs": [],
   "source": [
    "aeModel = AE()\n",
    "print(aeModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T12:24:31.176518Z",
     "start_time": "2020-11-01T12:24:30.791960Z"
    }
   },
   "outputs": [],
   "source": [
    "imageDataset = ImageDataset('trainX.npy')\n",
    "train_loader = DataLoader(imageDataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T12:36:23.848262Z",
     "start_time": "2020-11-01T12:36:23.840745Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(device):\n",
    "    aeModel = AE()\n",
    "    aeModel = aeModel.to(device) #!\n",
    "    return aeModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T12:24:36.535628Z",
     "start_time": "2020-11-01T12:24:36.497175Z"
    }
   },
   "outputs": [],
   "source": [
    "aeModel = build_model(device)\n",
    "print(aeModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train on batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:01:24.961598Z",
     "start_time": "2020-11-01T13:01:24.947881Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, train_loader, loss_function, device):\n",
    "    total_loss = 0.0\n",
    "    model.train()\n",
    "    \n",
    "    for i, data in enumerate(train_loader):\n",
    "\n",
    "        x = data.to(device)\n",
    "        code, x_hat = model(x)\n",
    "        \n",
    "        batch_loss = loss_function(x_hat, x)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += batch_loss.item()\n",
    "    \n",
    "#     avg_batch_loss = total_loss\n",
    "    avg_batch_loss = total_loss / len(train_loader) #? len(train_loader) = 幾個batch\n",
    "    \n",
    "    return model, optimizer, avg_batch_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T12:51:03.233425Z",
     "start_time": "2020-11-01T12:51:03.228607Z"
    }
   },
   "outputs": [],
   "source": [
    "# loss = nn.MSELoss()\n",
    "# input = torch.randn(2, 1, requires_grad=True)\n",
    "# target = torch.randn(2, 1)\n",
    "# output = loss(input, target)\n",
    "# output.backward()\n",
    "# input, target, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T12:37:05.058833Z",
     "start_time": "2020-11-01T12:36:59.202827Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imageDataset = ImageDataset('trainX.npy')\n",
    "train_loader = DataLoader(imageDataset, batch_size=64, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "aeModel = build_model(device)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(aeModel.parameters(), lr=1e-5, weight_decay=1e-5)\n",
    "\n",
    "aeModel, optimizer, train_loss = train_model(aeModel, optimizer, train_loader, loss_function, device) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T12:37:06.832517Z",
     "start_time": "2020-11-01T12:37:06.809603Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0035203646596740274"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train on epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:01:36.112869Z",
     "start_time": "2020-11-01T13:01:30.465518Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22341168565409525\n",
      "0.1810817953787352\n",
      "0.15120058870853337\n",
      "0.13091518528255305\n"
     ]
    }
   ],
   "source": [
    "imageDataset = ImageDataset('trainX.npy')\n",
    "train_loader = DataLoader(imageDataset, batch_size=64, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "aeModel = build_model(device)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(aeModel.parameters(), lr=1e-5, weight_decay=1e-5)\n",
    "\n",
    "for epoch in range(100):\n",
    "    aeModel, optimizer, train_loss = train_model(aeModel, optimizer, train_loader, loss_function, device) \n",
    "    print(epoch, train_loss)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        file_name = 'epoch_%s_loss_%s.pth'%(epoch, train_loss)\n",
    "        save_model(aeModel, file_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
