{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAO6SyjZbC27"
   },
   "source": [
    "# download file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-22T12:28:43.260569Z",
     "start_time": "2020-11-22T12:28:43.254782Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5425,
     "status": "ok",
     "timestamp": 1605435616948,
     "user": {
      "displayName": "RY Hung",
      "photoUrl": "",
      "userId": "04777645451313013800"
     },
     "user_tz": -480
    },
    "id": "fkOy-MCPZRwx",
    "outputId": "fde78ed9-7584-49b4-9941-b6dfa3886567"
   },
   "outputs": [],
   "source": [
    "# !gdown --id 1IGrTr308mGAaCKotpkkm8wTKlWs9Jq-p --output \"./crypko_data.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-22T12:28:43.340962Z",
     "start_time": "2020-11-22T12:28:43.291155Z"
    },
    "id": "imzoLtHVaSKP"
   },
   "outputs": [],
   "source": [
    "# !unzip -q \"./crypko_data.zip\" -d \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-22T12:28:43.407723Z",
     "start_time": "2020-11-22T12:28:43.345710Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 890,
     "status": "ok",
     "timestamp": 1605436620924,
     "user": {
      "displayName": "RY Hung",
      "photoUrl": "",
      "userId": "04777645451313013800"
     },
     "user_tz": -480
    },
    "id": "ttVmsjW2am0u",
    "outputId": "439b036f-33ae-449d-eeae-a7e9398a757d"
   },
   "outputs": [],
   "source": [
    "# !cd faces && ls -U | head -4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-22T12:28:43.593213Z",
     "start_time": "2020-11-22T12:28:43.412774Z"
    },
    "executionInfo": {
     "elapsed": 781,
     "status": "ok",
     "timestamp": 1605435890269,
     "user": {
      "displayName": "RY Hung",
      "photoUrl": "",
      "userId": "04777645451313013800"
     },
     "user_tz": -480
    },
    "id": "7Cr2NJ-San4m"
   },
   "outputs": [],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7blqwRWLcjay"
   },
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T18:55:56.690919Z",
     "start_time": "2020-11-29T18:55:55.572789Z"
    },
    "executionInfo": {
     "elapsed": 964,
     "status": "ok",
     "timestamp": 1605441204629,
     "user": {
      "displayName": "RY Hung",
      "photoUrl": "",
      "userId": "04777645451313013800"
     },
     "user_tz": -480
    },
    "id": "GxRbXsjMcm7F"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pBA4zgEQcnLE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KTstTC9pbGom"
   },
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGPy8dEOcpN2"
   },
   "source": [
    "## check file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T11:50:47.751873Z",
     "start_time": "2020-11-29T11:50:47.745870Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 1012,
     "status": "ok",
     "timestamp": 1605436764586,
     "user": {
      "displayName": "RY Hung",
      "photoUrl": "",
      "userId": "04777645451313013800"
     },
     "user_tz": -480
    },
    "id": "LhwmlM1Ias6p",
    "outputId": "8c2d4391-c88b-4eb9-ae51-bc36b43af3fa"
   },
   "outputs": [],
   "source": [
    "dir_name = '/workdir/home/feynman52/NTU-ML2020/hw11-gan/datasets/faces'\n",
    "file_name = '33077.jpg'\n",
    "file_path = os.path.join(dir_name, file_name)\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T11:50:47.805129Z",
     "start_time": "2020-11-29T11:50:47.753787Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 989,
     "status": "ok",
     "timestamp": 1605440490950,
     "user": {
      "displayName": "RY Hung",
      "photoUrl": "",
      "userId": "04777645451313013800"
     },
     "user_tz": -480
    },
    "id": "X5Ud7jYjaww9",
    "outputId": "365658e7-fe9b-4657-ce9d-eeb09c144959"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(file_path)\n",
    "img.shape, type(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T11:50:47.980135Z",
     "start_time": "2020-11-29T11:50:47.809144Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "executionInfo": {
     "elapsed": 943,
     "status": "ok",
     "timestamp": 1605440547826,
     "user": {
      "displayName": "RY Hung",
      "photoUrl": "",
      "userId": "04777645451313013800"
     },
     "user_tz": -480
    },
    "id": "ML_C_tRvtpf6",
    "outputId": "2876027f-49c9-489a-d213-ad4603ca331a"
   },
   "outputs": [],
   "source": [
    "plt.imshow(img, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T11:50:47.984561Z",
     "start_time": "2020-11-29T11:50:47.981901Z"
    },
    "executionInfo": {
     "elapsed": 751,
     "status": "ok",
     "timestamp": 1605441255940,
     "user": {
      "displayName": "RY Hung",
      "photoUrl": "",
      "userId": "04777645451313013800"
     },
     "user_tz": -480
    },
    "id": "JQHf-lyJwTn5"
   },
   "outputs": [],
   "source": [
    "# glob('./faces/*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PH9yzSQPtGBy"
   },
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T18:56:02.948614Z",
     "start_time": "2020-11-29T18:56:02.928902Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.data = list(range(10))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "        \n",
    "        \n",
    "testDataset = TestDataset()\n",
    "len(testDataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0, 1, 2, 3, 4, 5]\n",
    "\n",
    "[5, 1, 2, 0, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T13:36:53.114002Z",
     "start_time": "2020-11-29T13:36:53.100926Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "t_loader = DataLoader(testDataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for i, xy in enumerate(t_loader):\n",
    "    print(xy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T13:37:41.450520Z",
     "start_time": "2020-11-29T13:37:41.437683Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "t_loader = DataLoader(testDataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for epoch in range(3):\n",
    "    xy = next(iter(t_loader))\n",
    "    print(xy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T18:56:06.633422Z",
     "start_time": "2020-11-29T18:56:06.414435Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1021,
     "status": "ok",
     "timestamp": 1605443157588,
     "user": {
      "displayName": "RY Hung",
      "photoUrl": "",
      "userId": "04777645451313013800"
     },
     "user_tz": -480
    },
    "id": "d6Qwy0FFtLHp",
    "outputId": "6b475170-c9ab-44a9-f608-c9384b596c98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71314"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FaceDataset(Dataset):\n",
    "    def __init__(self, img_dir='/workdir/home/feynman52/NTU-ML2020/hw11-gan/datasets/faces', ):\n",
    "        self.img_dir = img_dir\n",
    "        self.setup()\n",
    "\n",
    "    def setup(self):\n",
    "        self.setup_data()\n",
    "        self.setup_transform()\n",
    "\n",
    "    def setup_data(self):\n",
    "        self.data = glob(os.path.join(self.img_dir, '*'))[:]\n",
    "\n",
    "    def setup_transform(self):\n",
    "        transform_steps = [transforms.ToPILImage(),\n",
    "                            transforms.Resize((64, 64)),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize(mean=[0.5] * 3, std=[0.5] * 3) ]\n",
    "        self.transform_fn = transforms.Compose(transform_steps)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data[idx]\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = self.transform_fn(img)\n",
    "        return img\n",
    "\n",
    "faceDataset = FaceDataset()\n",
    "len(faceDataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r-gyRTT5tIFv"
   },
   "source": [
    "## dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T12:24:57.366353Z",
     "start_time": "2020-11-29T12:24:57.172128Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 858,
     "status": "ok",
     "timestamp": 1605443160107,
     "user": {
      "displayName": "RY Hung",
      "photoUrl": "",
      "userId": "04777645451313013800"
     },
     "user_tz": -480
    },
    "id": "QjW63DUC28j_",
    "outputId": "5d90da7a-4d7f-49db-f09c-ccce67011e08"
   },
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "train_loader = DataLoader(faceDataset, batch_size=batch_size, shuffle=True)\n",
    "x = next(iter(train_loader))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IznWbWJvbJAW"
   },
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T18:56:11.173045Z",
     "start_time": "2020-11-29T18:56:11.147594Z"
    },
    "executionInfo": {
     "elapsed": 794,
     "status": "ok",
     "timestamp": 1605444751895,
     "user": {
      "displayName": "RY Hung",
      "photoUrl": "",
      "userId": "04777645451313013800"
     },
     "user_tz": -480
    },
    "id": "upT8ErM6aySj"
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "        \n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "class NetG(nn.Module):\n",
    "    def __init__(self, in_dim, dim=64):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "        self.in_dim = in_dim\n",
    "        self.setup_layer()  \n",
    "        self.apply(weights_init)\n",
    "    \n",
    "    def setup_layer(self):\n",
    "        self.l1 = nn.Sequential(nn.Linear(self.in_dim, self.dim * 8 * 4 * 4, bias=False),\n",
    "                                nn.BatchNorm1d(self.dim * 8 * 4 * 4),\n",
    "                                nn.ReLU())\n",
    "        \n",
    "        self.l2_5 = nn.Sequential(self.dconv_bn_relu(self.dim * 8, self.dim * 4),\n",
    "                                    self.dconv_bn_relu(self.dim * 4, self.dim * 2),\n",
    "                                    self.dconv_bn_relu(self.dim * 2, self.dim),\n",
    "                                    nn.ConvTranspose2d(self.dim, 3, 5, 2, padding=2, output_padding=1),\n",
    "                                    nn.Tanh())\n",
    "\n",
    "    def dconv_bn_relu(self, in_dim, out_dim):\n",
    "        convTranspose2d = nn.ConvTranspose2d(in_dim, out_dim, \n",
    "                                            5, 2,\n",
    "                                            padding=2, \n",
    "                                            output_padding=1, \n",
    "                                            bias=False)\n",
    "        net = nn.Sequential(convTranspose2d,\n",
    "                            nn.BatchNorm2d(out_dim),\n",
    "                            nn.ReLU())\n",
    "        return net\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.l1(x)\n",
    "        y = y.view(y.size(0), -1, 4, 4)\n",
    "        y = self.l2_5(y)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T18:56:16.042335Z",
     "start_time": "2020-11-29T18:56:16.024519Z"
    },
    "executionInfo": {
     "elapsed": 1039,
     "status": "ok",
     "timestamp": 1605443171732,
     "user": {
      "displayName": "RY Hung",
      "photoUrl": "",
      "userId": "04777645451313013800"
     },
     "user_tz": -480
    },
    "id": "2rgKWGFwaydM"
   },
   "outputs": [],
   "source": [
    "class NetD(nn.Module):\n",
    "    def __init__(self, in_dim, dim=64):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "        self.in_dim = in_dim\n",
    "        self.setup_layer()\n",
    "        self.apply(weights_init)  \n",
    "    \n",
    "    def setup_layer(self):\n",
    "        self.ls = nn.Sequential(nn.Conv2d(self.in_dim, self.dim, 5, 2, 2), \n",
    "                                nn.LeakyReLU(0.2),\n",
    "                                self.conv_bn_lrelu(self.dim, self.dim * 2),\n",
    "                                self.conv_bn_lrelu(self.dim * 2, self.dim * 4),\n",
    "                                self.conv_bn_lrelu(self.dim * 4, self.dim * 8),\n",
    "                                nn.Conv2d(self.dim * 8, 1, 4),\n",
    "                                nn.Sigmoid())\n",
    "        \n",
    "    def conv_bn_lrelu(self, in_dim, out_dim):\n",
    "        net = nn.Sequential(nn.Conv2d(in_dim, out_dim, 5, 2, 2),\n",
    "                            nn.BatchNorm2d(out_dim),\n",
    "                            nn.LeakyReLU(0.2))\n",
    "        return net\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.ls(x)\n",
    "        y = y.view(-1)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "thOiSB--aygW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GK-cqZyQayjV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KUNA2y-ObNYU"
   },
   "source": [
    "# train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T18:56:20.066734Z",
     "start_time": "2020-11-29T18:56:20.060099Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T18:56:22.324939Z",
     "start_time": "2020-11-29T18:56:22.288464Z"
    },
    "id": "QgoaTPjRaymo"
   },
   "outputs": [],
   "source": [
    "class TrainAndTest:\n",
    "    def __init__(self, option):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.option = option\n",
    "        self.setup()\n",
    "\n",
    "    def setup(self):\n",
    "        self.setup_data()\n",
    "        self.setup_model()\n",
    "        self.setup_optimizer()\n",
    "        self.setup_criterion()\n",
    "        self.setup_history()\n",
    "\n",
    "    def setup_data(self):\n",
    "        faceDataset = FaceDataset()\n",
    "        self.train_loader = DataLoader(faceDataset, batch_size=self.option.batch_size, shuffle=True)\n",
    "\n",
    "    def setup_model(self):\n",
    "        self.netG = NetG(in_dim=self.option.z_dim).to(self.device) #!\n",
    "        self.netD = NetD(3).to(self.device) #!\n",
    "\n",
    "    def setup_optimizer(self):\n",
    "        self.optimizer_G = torch.optim.Adam(self.netG.parameters(), lr=self.option.lr, betas=(0.5, 0.999))\n",
    "        self.optimizer_D = torch.optim.Adam(self.netD.parameters(), lr=self.option.lr, betas=(0.5, 0.999))\n",
    "\n",
    "    def setup_criterion(self):\n",
    "        self.criterion = nn.BCELoss()\n",
    "\n",
    "    def setup_history(self,):\n",
    "        self.df_history = pd.DataFrame()\n",
    "        \n",
    "    def train_one_epoch(self):\n",
    "        loss_G = 0.0\n",
    "        loss_D = 0.0\n",
    "        \n",
    "        for i, x_y in enumerate(self.train_loader):\n",
    "            batch_loss_G, batch_loss_D = train_one_batch(self, x_y)\n",
    "            loss_G += batch_loss_G\n",
    "            loss_D += batch_loss_D\n",
    "\n",
    "        loss_G /= len(self.train_loader)\n",
    "        loss_D /= len(self.train_loader)\n",
    "        return loss_G, loss_D\n",
    "\n",
    "    def train_one_batch(self, x_y):\n",
    "        self.netG.train()\n",
    "        self.netD.train()\n",
    "\n",
    "        \"\"\" Train D \"\"\"\n",
    "        # img\n",
    "        x = x_y.to(self.device)\n",
    "        batch_size = len(x)\n",
    "        z = Variable(torch.randn(batch_size, self.option.z_dim)).to(self.device)\n",
    "\n",
    "        r_imgs = Variable(x)\n",
    "        f_imgs = self.netG(z)\n",
    "\n",
    "        # label\n",
    "        r_label = torch.ones((batch_size)).to(self.device)\n",
    "        f_label = torch.zeros((batch_size)).to(self.device)\n",
    "\n",
    "        # D\n",
    "        r_logit = self.netD(r_imgs)\n",
    "        f_logit = self.netD(f_imgs)\n",
    "\n",
    "        # compute loss\n",
    "        r_loss = self.criterion(r_logit, r_label)\n",
    "        f_loss = self.criterion(f_logit, f_label)\n",
    "        batch_loss_D = (r_loss + f_loss) / 2\n",
    "\n",
    "        self.optimizer_D.zero_grad()\n",
    "        batch_loss_D.backward()\n",
    "        self.optimizer_D.step()\n",
    "\n",
    "        batch_loss_D = batch_loss_D.item()\n",
    "\n",
    "\n",
    "        \"\"\" train G \"\"\"\n",
    "        # leaf\n",
    "        z = Variable(torch.randn(batch_size, self.option.z_dim)).to(self.device)\n",
    "        f_imgs = self.netG(z)\n",
    "\n",
    "        # dis\n",
    "        f_logit = self.netD(f_imgs)\n",
    "\n",
    "        # compute loss\n",
    "        batch_loss_G = self.criterion(f_logit, r_label)\n",
    "\n",
    "        # update model\n",
    "        self.netG.zero_grad()\n",
    "        batch_loss_G.backward()\n",
    "        self.optimizer_G.step()\n",
    "\n",
    "        batch_loss_G = batch_loss_G.item()\n",
    "        \n",
    "        return batch_loss_G, batch_loss_D\n",
    "    \n",
    "    def sample_imgs(self, epoch=None):\n",
    "        file_name = 'epoch-%s---model-netG.pth'%(epoch)\n",
    "        path = os.path.join('.', 'weights', file_name)\n",
    "        \n",
    "        model = self.netG\n",
    "        model.load_state_dict(torch.load(path))\n",
    "        model.eval()\n",
    "        \n",
    "        batch_size = 20\n",
    "        z_sample = Variable(torch.randn(batch_size, self.option.z_dim)).to(self.device)\n",
    "        imgs_sample = model(z_sample)\n",
    "        \n",
    "        imgs = imgs_sample.detach().cpu().numpy() # detach gradient, gpu to cpu, tensor to numpy\n",
    "        imgs = (imgs + 1) / 2.0 #?\n",
    "        '''\n",
    "        -1 ~ 1\n",
    "        0 ~ 2\n",
    "        0 ~ 1\n",
    "        '''\n",
    "        return imgs\n",
    "        \n",
    "    \n",
    "    def save_model(self, epoch, loss_G, loss_D):\n",
    "        file_name = 'epoch-%s---model-netG.pth'%(epoch)\n",
    "        path = os.path.join('.', 'weights', file_name)\n",
    "        torch.save(self.netG.state_dict(), path)\n",
    "        \n",
    "        file_name = 'epoch-%s---model-netD.pth'%(epoch)\n",
    "        path = os.path.join('.', 'weights', file_name)\n",
    "        torch.save(self.netD.state_dict(), path)\n",
    "        \n",
    "        # history\n",
    "        row = pd.DataFrame()\n",
    "        row['epoch'] = [epoch]\n",
    "        row['loss_G'] = [loss_G]\n",
    "        row['loss_D'] = [loss_D]\n",
    "        self.df_history = self.df_history.append(row)\n",
    "        self.df_history.to_csv(os.path.join('.', 'weights', 'df_history.csv'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.1, 0.9] [0.1, 0.9]\n",
    "[0.4, 0.6] [0.4, 0.6]\n",
    "\n",
    "[0.5, 0.5] [0.5, 0.5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T18:56:27.392793Z",
     "start_time": "2020-11-29T18:56:27.381037Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Option:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 64\n",
    "        self.z_dim = 100\n",
    "        self.lr = 1e-4\n",
    "        self.n_epoch = 10\n",
    "\n",
    "option = Option()\n",
    "option.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T18:56:50.549350Z",
     "start_time": "2020-11-29T18:56:46.248706Z"
    }
   },
   "outputs": [],
   "source": [
    "trainAndTest = TrainAndTest(option)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-29T18:56:52.155Z"
    },
    "id": "4CG6zpvxayrD",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.283 0.895\n",
      "1 5.384 0.203\n",
      "2 5.737 0.083\n",
      "3 5.376 0.072\n",
      "4 5.905 0.083\n",
      "5 5.779 0.107\n",
      "6 5.933 0.049\n",
      "7 5.974 0.076\n",
      "8 6.713 0.057\n",
      "9 6.742 0.038\n",
      "10 6.217 0.043\n",
      "11 7.127 0.05\n",
      "12 6.955 0.046\n",
      "13 7.327 0.03\n",
      "14 7.207 0.028\n",
      "15 7.238 0.046\n",
      "16 7.652 0.061\n",
      "17 6.484 0.049\n",
      "18 8.227 0.042\n",
      "19 7.823 0.026\n",
      "20 7.006 0.013\n",
      "21 8.493 0.037\n",
      "22 7.932 0.02\n",
      "23 7.47 0.029\n",
      "24 10.161 0.034\n",
      "25 7.611 0.071\n",
      "26 8.523 0.037\n",
      "27 8.657 0.02\n",
      "28 8.622 0.011\n",
      "29 8.726 0.013\n",
      "30 7.402 0.024\n",
      "31 10.465 0.047\n",
      "32 9.4 0.012\n",
      "33 7.62 0.006\n",
      "34 9.769 0.021\n",
      "35 8.219 0.015\n",
      "36 8.033 0.013\n",
      "37 8.297 0.023\n",
      "38 7.881 0.025\n",
      "39 9.587 0.033\n",
      "40 9.083 0.007\n",
      "41 7.757 0.02\n",
      "42 11.777 0.039\n",
      "43 7.6 0.027\n",
      "44 11.27 0.019\n",
      "45 9.641 0.017\n",
      "46 7.036 0.008\n",
      "47 19.479 0.04\n",
      "48 1.558 0.403\n",
      "49 30.723 1.125\n",
      "50 37.258 0.123\n",
      "51 37.88 0.332\n",
      "52 36.388 0.244\n",
      "53 35.43 0.002\n",
      "54 35.075 0.001\n",
      "55 34.564 0.0\n",
      "56 34.651 0.0\n",
      "57 34.547 0.0\n",
      "58 34.402 0.0\n",
      "59 34.283 0.001\n",
      "60 34.371 0.0\n",
      "61 34.456 0.0\n",
      "62 34.284 0.0\n",
      "63 34.274 0.0\n",
      "64 34.079 0.0\n",
      "65 34.333 0.0\n",
      "66 34.152 0.0\n",
      "67 34.094 0.0\n",
      "68 33.867 0.0\n",
      "69 33.923 0.0\n",
      "70 33.79 0.0\n",
      "71 33.78 0.0\n",
      "72 33.653 0.0\n",
      "73 33.475 0.0\n",
      "74 33.348 0.0\n",
      "75 33.306 0.0\n",
      "76 33.162 0.0\n",
      "77 32.773 0.0\n",
      "78 32.563 0.0\n",
      "79 32.408 0.0\n",
      "80 32.1 0.0\n",
      "81 31.629 0.0\n",
      "82 30.899 0.0\n",
      "83 30.083 0.0\n",
      "84 28.127 0.0\n",
      "85 23.681 0.0\n",
      "86 14.012 0.0\n",
      "87 10.98 0.042\n",
      "88 19.58 0.078\n",
      "89 20.193 0.017\n",
      "90 15.071 0.059\n",
      "91 7.204 0.037\n",
      "92 34.41 0.611\n",
      "93 34.587 1.616\n",
      "94 33.508 0.048\n",
      "95 32.799 0.001\n",
      "96 32.141 0.0\n",
      "97 31.845 0.0\n",
      "98 31.093 0.0\n",
      "99 30.432 0.0\n",
      "100 29.017 0.0\n",
      "101 26.197 0.0\n",
      "102 19.205 0.0\n",
      "103 11.201 0.0\n",
      "104 10.047 0.056\n",
      "105 12.599 0.048\n",
      "106 11.148 0.022\n",
      "107 8.928 0.038\n",
      "108 24.934 0.266\n",
      "109 24.465 0.496\n",
      "110 17.142 0.32\n",
      "111 6.659 0.013\n",
      "112 31.713 1.588\n",
      "113 36.186 0.536\n",
      "114 36.218 0.486\n",
      "115 35.771 0.102\n",
      "116 34.9 0.019\n",
      "117 34.331 0.005\n",
      "118 34.122 0.001\n",
      "119 34.268 0.0\n",
      "120 33.725 0.0\n",
      "121 33.472 0.0\n",
      "122 33.6 0.003\n",
      "123 33.16 0.002\n",
      "124 32.729 0.0\n",
      "125 32.888 0.0\n",
      "126 32.391 0.0\n",
      "127 31.499 0.0\n",
      "128 31.08 0.0\n",
      "129 30.162 0.0\n",
      "130 28.96 0.0\n",
      "131 25.589 0.0\n",
      "132 18.183 0.0\n",
      "133 7.374 0.007\n",
      "134 25.477 0.711\n",
      "135 30.015 0.008\n",
      "136 28.883 0.272\n",
      "137 26.854 0.043\n",
      "138 21.86 0.112\n",
      "139 14.185 0.064\n",
      "140 18.517 0.497\n",
      "141 14.391 0.171\n",
      "142 9.308 0.305\n",
      "143 14.641 0.478\n",
      "144 11.599 0.311\n",
      "145 6.945 0.042\n",
      "146 7.704 0.075\n",
      "147 7.801 0.07\n",
      "148 6.711 0.181\n",
      "149 8.096 0.076\n",
      "150 8.407 0.025\n",
      "151 8.099 0.049\n",
      "152 11.804 0.077\n",
      "153 9.32 0.072\n",
      "154 8.166 0.116\n",
      "155 13.978 0.169\n",
      "156 10.409 0.243\n",
      "157 6.089 0.071\n",
      "158 25.792 0.451\n",
      "159 28.581 0.26\n",
      "160 27.843 0.117\n",
      "161 25.342 0.057\n",
      "162 19.727 0.044\n",
      "163 10.614 0.002\n",
      "164 11.629 0.131\n",
      "165 10.678 0.015\n",
      "166 7.265 0.065\n",
      "167 18.184 0.387\n",
      "168 14.049 0.585\n",
      "169 3.536 0.304\n",
      "170 24.696 1.608\n",
      "171 27.697 0.453\n",
      "172 23.029 0.611\n",
      "173 17.987 0.015\n",
      "174 13.062 0.005\n",
      "175 8.176 0.004\n",
      "176 6.222 0.054\n",
      "177 11.382 0.219\n",
      "178 12.196 0.014\n",
      "179 9.572 0.023\n",
      "180 6.417 0.146\n",
      "181 11.832 0.299\n",
      "182 8.972 0.465\n",
      "183 5.759 0.067\n",
      "184 8.899 0.137\n",
      "185 8.075 0.079\n",
      "186 5.61 0.039\n",
      "187 7.166 0.232\n",
      "188 8.256 0.2\n",
      "189 8.561 0.369\n",
      "190 5.51 0.574\n",
      "191 10.981 0.279\n",
      "192 9.759 0.15\n",
      "193 6.106 0.038\n",
      "194 9.361 0.18\n",
      "195 7.061 0.184\n",
      "196 5.687 0.102\n",
      "197 7.702 0.221\n",
      "198 5.815 0.119\n",
      "199 7.36 0.12\n",
      "200 6.248 0.047\n",
      "201 6.019 0.061\n",
      "202 4.737 0.105\n",
      "203 7.85 0.238\n",
      "204 5.81 0.116\n",
      "205 4.261 0.211\n",
      "206 9.087 0.185\n",
      "207 5.706 0.32\n",
      "208 7.195 0.104\n",
      "209 5.613 0.075\n",
      "210 8.835 0.195\n",
      "211 5.542 0.25\n",
      "212 10.266 0.327\n",
      "213 7.656 0.214\n",
      "214 4.573 0.194\n",
      "215 14.617 0.464\n",
      "216 11.806 0.398\n",
      "217 5.277 0.238\n",
      "218 10.039 0.285\n",
      "219 10.985 0.034\n",
      "220 8.488 0.155\n",
      "221 6.682 0.093\n",
      "222 11.849 0.52\n",
      "223 9.723 0.333\n",
      "224 6.5 0.206\n",
      "225 11.01 0.368\n",
      "226 7.092 0.279\n",
      "227 12.558 0.396\n",
      "228 5.723 0.495\n",
      "229 8.196 0.348\n",
      "230 7.142 0.199\n",
      "231 7.245 0.147\n",
      "232 4.936 0.169\n",
      "233 8.17 0.348\n",
      "234 5.004 0.325\n",
      "235 6.437 0.235\n",
      "236 7.179 0.048\n",
      "237 5.66 0.155\n",
      "238 7.512 0.123\n",
      "239 5.779 0.186\n",
      "240 11.902 0.383\n",
      "241 8.268 0.338\n",
      "242 5.683 0.25\n",
      "243 4.496 0.115\n",
      "244 5.443 0.085\n",
      "245 5.499 0.226\n",
      "246 5.524 0.067\n",
      "247 5.007 0.135\n",
      "248 5.185 0.135\n",
      "249 5.829 0.149\n",
      "250 5.172 0.142\n",
      "251 7.542 0.29\n",
      "252 3.047 0.42\n",
      "253 12.318 0.605\n",
      "254 7.456 1.181\n",
      "255 2.949 0.087\n",
      "256 13.856 0.853\n",
      "257 14.976 0.276\n",
      "258 9.003 0.658\n",
      "259 3.787 0.033\n",
      "260 9.89 0.714\n",
      "261 9.863 0.082\n",
      "262 5.941 0.186\n",
      "263 8.436 0.491\n",
      "264 5.92 0.375\n",
      "265 3.577 0.32\n",
      "266 10.314 0.494\n",
      "267 7.491 0.53\n",
      "268 4.02 0.15\n",
      "269 9.463 0.415\n",
      "270 9.379 0.11\n",
      "271 5.739 0.113\n",
      "272 6.044 0.317\n",
      "273 5.107 0.22\n",
      "274 5.598 0.106\n",
      "275 5.836 0.079\n",
      "276 5.772 0.121\n",
      "277 6.472 0.147\n",
      "278 5.932 0.17\n",
      "279 6.441 0.091\n",
      "280 6.178 0.032\n",
      "281 3.546 0.264\n",
      "282 5.159 0.145\n",
      "283 5.782 0.057\n",
      "284 5.491 0.02\n",
      "285 4.972 0.06\n",
      "286 4.469 0.085\n",
      "287 5.154 0.086\n",
      "288 4.75 0.085\n",
      "289 3.979 0.115\n",
      "290 5.565 0.089\n",
      "291 5.045 0.084\n",
      "292 3.549 0.171\n",
      "293 7.606 0.199\n",
      "294 6.997 0.229\n",
      "295 4.456 0.093\n",
      "296 7.026 0.206\n",
      "297 5.301 0.135\n",
      "298 5.058 0.085\n",
      "299 5.543 0.221\n",
      "300 6.772 0.12\n",
      "301 5.565 0.169\n",
      "302 5.593 0.184\n",
      "303 7.412 0.142\n",
      "304 6.215 0.138\n",
      "305 6.622 0.179\n",
      "306 7.614 0.15\n",
      "307 6.351 0.118\n",
      "308 9.488 0.295\n",
      "309 8.043 0.1\n",
      "310 6.203 0.152\n",
      "311 9.504 0.349\n",
      "312 6.675 0.21\n",
      "313 5.425 0.127\n",
      "314 6.142 0.197\n",
      "315 6.538 0.071\n",
      "316 6.159 0.047\n",
      "317 7.865 0.145\n",
      "318 6.792 0.108\n",
      "319 6.413 0.229\n",
      "320 5.661 0.183\n",
      "321 4.316 0.345\n",
      "322 5.4 0.237\n",
      "323 4.321 0.176\n",
      "324 5.055 0.159\n",
      "325 5.199 0.149\n",
      "326 5.674 0.143\n",
      "327 5.715 0.099\n",
      "328 4.82 0.103\n",
      "329 4.874 0.11\n",
      "330 5.399 0.09\n",
      "331 5.419 0.075\n",
      "332 5.358 0.056\n",
      "333 5.833 0.032\n",
      "334 5.765 0.032\n",
      "335 5.441 0.041\n",
      "336 5.587 0.039\n",
      "337 4.961 0.085\n",
      "338 5.008 0.073\n",
      "339 4.97 0.088\n",
      "340 5.325 0.103\n",
      "341 5.958 0.065\n",
      "342 4.991 0.137\n",
      "343 6.341 0.151\n",
      "344 5.456 0.165\n",
      "345 6.532 0.189\n",
      "346 5.692 0.153\n",
      "347 5.303 0.137\n",
      "348 6.178 0.14\n",
      "349 6.064 0.048\n",
      "350 4.018 0.152\n",
      "351 7.705 0.245\n",
      "352 6.379 0.166\n",
      "353 3.743 0.163\n",
      "354 10.08 0.264\n",
      "355 11.853 0.066\n",
      "356 7.436 0.387\n",
      "357 3.767 0.081\n",
      "358 4.678 0.078\n",
      "359 6.138 0.039\n",
      "360 6.43 0.084\n",
      "361 5.89 0.018\n",
      "362 4.975 0.027\n",
      "363 5.156 0.056\n",
      "364 5.588 0.043\n",
      "365 5.472 0.056\n",
      "366 5.667 0.052\n",
      "367 4.318 0.158\n",
      "368 5.808 0.136\n",
      "369 5.949 0.06\n",
      "370 4.561 0.158\n",
      "371 4.858 0.163\n",
      "372 6.388 0.131\n",
      "373 6.548 0.037\n",
      "374 5.056 0.203\n",
      "375 9.551 0.335\n",
      "376 9.542 0.068\n",
      "377 7.512 0.037\n",
      "378 5.104 0.061\n",
      "379 5.161 0.055\n",
      "380 5.672 0.048\n",
      "381 5.522 0.076\n",
      "382 5.373 0.044\n",
      "383 4.876 0.049\n",
      "384 6.644 0.055\n",
      "385 6.456 0.028\n",
      "386 6.332 0.057\n",
      "387 7.488 0.119\n",
      "388 6.44 0.059\n",
      "389 5.961 0.143\n",
      "390 6.406 0.071\n",
      "391 5.333 0.139\n",
      "392 6.267 0.081\n",
      "393 5.5 0.102\n",
      "394 7.421 0.101\n",
      "395 5.496 0.077\n",
      "396 4.596 0.132\n",
      "397 4.506 0.087\n",
      "398 5.132 0.05\n",
      "399 6.76 0.132\n",
      "400 6.592 0.069\n",
      "401 5.445 0.119\n",
      "402 5.869 0.149\n",
      "403 6.108 0.08\n",
      "404 4.843 0.084\n",
      "405 2.521 0.186\n",
      "406 10.401 0.336\n",
      "407 9.0 0.233\n",
      "408 4.652 0.146\n",
      "409 4.207 0.086\n",
      "410 8.711 0.189\n",
      "411 5.067 0.304\n",
      "412 5.923 0.264\n",
      "413 6.251 0.09\n",
      "414 5.438 0.109\n",
      "415 5.279 0.094\n",
      "416 5.324 0.134\n",
      "417 7.422 0.156\n",
      "418 6.573 0.118\n",
      "419 7.548 0.425\n",
      "420 6.755 0.263\n",
      "421 2.366 0.396\n",
      "422 19.983 0.649\n",
      "423 10.561 2.288\n",
      "424 3.3 0.154\n",
      "425 11.867 2.039\n",
      "426 10.579 0.379\n",
      "427 4.865 0.319\n",
      "428 8.677 0.743\n",
      "429 7.475 0.362\n",
      "430 5.461 0.104\n",
      "431 8.97 0.362\n",
      "432 8.721 0.167\n",
      "433 6.834 0.242\n",
      "434 9.243 0.311\n",
      "435 8.263 0.25\n",
      "436 7.096 0.317\n",
      "437 5.237 0.21\n",
      "438 4.698 0.364\n",
      "439 6.764 0.153\n",
      "440 4.837 0.154\n",
      "441 5.678 0.204\n",
      "442 4.807 0.127\n",
      "443 4.958 0.095\n",
      "444 5.411 0.154\n",
      "445 5.015 0.111\n",
      "446 5.475 0.137\n",
      "447 4.662 0.152\n",
      "448 4.193 0.115\n",
      "449 5.984 0.173\n",
      "450 4.508 0.154\n",
      "451 5.673 0.238\n",
      "452 5.996 0.133\n",
      "453 6.12 0.177\n",
      "454 4.773 0.188\n",
      "455 6.126 0.251\n",
      "456 4.503 0.219\n",
      "457 7.658 0.305\n",
      "458 5.022 0.271\n",
      "459 8.005 0.304\n",
      "460 5.061 0.417\n",
      "461 5.585 0.161\n",
      "462 5.995 0.104\n",
      "463 6.293 0.114\n",
      "464 5.566 0.216\n",
      "465 5.963 0.22\n",
      "466 4.372 0.284\n",
      "467 9.31 0.298\n",
      "468 7.655 0.209\n",
      "469 4.072 0.108\n",
      "470 8.568 0.337\n",
      "471 7.712 0.189\n",
      "472 4.887 0.115\n",
      "473 6.78 0.204\n",
      "474 6.164 0.12\n",
      "475 4.496 0.11\n",
      "476 4.707 0.177\n",
      "477 4.675 0.134\n",
      "478 4.488 0.069\n",
      "479 4.507 0.141\n",
      "480 5.241 0.089\n",
      "481 3.438 0.207\n",
      "482 7.372 0.236\n",
      "483 4.814 0.268\n",
      "484 3.688 0.153\n",
      "485 7.017 0.224\n",
      "486 5.471 0.177\n",
      "487 3.162 0.18\n",
      "488 6.005 0.26\n",
      "489 6.127 0.09\n",
      "490 4.678 0.117\n",
      "491 4.268 0.154\n",
      "492 4.931 0.171\n",
      "493 3.475 0.138\n",
      "494 5.129 0.172\n",
      "495 4.999 0.107\n",
      "496 4.109 0.105\n",
      "497 4.117 0.134\n",
      "498 5.288 0.142\n",
      "499 5.471 0.178\n",
      "500 3.756 0.181\n",
      "501 5.856 0.217\n",
      "502 4.237 0.207\n",
      "503 7.598 0.354\n",
      "504 1.459 0.641\n",
      "505 14.399 1.253\n",
      "506 9.593 1.4\n",
      "507 3.957 0.09\n",
      "508 8.472 0.545\n",
      "509 8.737 0.033\n",
      "510 5.583 0.18\n",
      "511 4.19 0.217\n",
      "512 5.76 0.229\n",
      "513 3.071 0.496\n",
      "514 9.3 0.443\n",
      "515 7.06 0.281\n",
      "516 3.199 0.423\n",
      "517 10.455 0.73\n",
      "518 5.468 1.019\n",
      "519 3.572 0.13\n",
      "520 7.422 0.466\n",
      "521 6.427 0.267\n",
      "522 3.154 0.183\n",
      "523 6.737 0.448\n",
      "524 5.209 0.298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525 3.814 0.149\n",
      "526 5.385 0.211\n",
      "527 4.593 0.203\n",
      "528 3.845 0.286\n",
      "529 3.882 0.293\n",
      "530 4.211 0.188\n",
      "531 3.833 0.197\n",
      "532 4.271 0.182\n",
      "533 4.287 0.184\n",
      "534 4.982 0.129\n",
      "535 4.298 0.155\n",
      "536 4.163 0.312\n",
      "537 4.626 0.21\n",
      "538 3.665 0.165\n",
      "539 2.932 0.234\n",
      "540 5.005 0.236\n",
      "541 4.262 0.184\n",
      "542 2.935 0.204\n",
      "543 6.395 0.211\n",
      "544 4.599 0.214\n",
      "545 2.969 0.183\n",
      "546 5.713 0.247\n",
      "547 4.193 0.239\n",
      "548 3.659 0.28\n",
      "549 4.667 0.326\n",
      "550 4.372 0.371\n",
      "551 2.401 0.496\n",
      "552 7.96 0.5\n",
      "553 3.821 0.546\n",
      "554 3.818 0.258\n",
      "555 4.639 0.167\n",
      "556 4.593 0.314\n",
      "557 5.082 0.196\n",
      "558 3.148 0.341\n",
      "559 5.727 0.359\n",
      "560 3.9 0.3\n",
      "561 5.296 0.23\n",
      "562 3.051 0.292\n",
      "563 4.845 0.276\n",
      "564 5.064 0.17\n",
      "565 2.14 0.264\n",
      "566 8.532 0.46\n",
      "567 3.682 0.648\n",
      "568 1.727 0.203\n",
      "569 8.927 0.43\n",
      "570 6.309 0.405\n",
      "571 3.125 0.105\n",
      "572 5.51 0.307\n",
      "573 4.762 0.177\n",
      "574 3.023 0.191\n",
      "575 6.105 0.35\n",
      "576 3.503 0.341\n",
      "577 5.298 0.286\n",
      "578 2.909 0.272\n",
      "579 7.548 0.334\n",
      "580 4.755 0.315\n",
      "581 4.083 0.12\n",
      "582 5.755 0.182\n",
      "583 5.19 0.151\n",
      "584 3.498 0.172\n",
      "585 6.309 0.29\n",
      "586 5.439 0.136\n",
      "587 3.238 0.191\n",
      "588 5.488 0.196\n",
      "589 4.419 0.101\n",
      "590 3.637 0.147\n",
      "591 4.855 0.19\n",
      "592 4.632 0.132\n",
      "593 3.265 0.25\n",
      "594 6.369 0.266\n",
      "595 3.839 0.256\n",
      "596 5.305 0.229\n",
      "597 5.963 0.122\n",
      "598 4.308 0.134\n",
      "599 7.649 0.248\n",
      "600 2.562 0.552\n",
      "601 9.821 0.503\n",
      "602 9.863 0.183\n",
      "603 4.41 0.211\n",
      "604 5.379 0.264\n",
      "605 6.997 0.216\n",
      "606 4.952 0.181\n",
      "607 5.334 0.124\n",
      "608 5.469 0.124\n",
      "609 5.369 0.097\n",
      "610 3.308 0.218\n",
      "611 6.336 0.177\n",
      "612 5.844 0.104\n",
      "613 5.114 0.068\n",
      "614 4.249 0.087\n",
      "615 4.932 0.116\n",
      "616 4.765 0.132\n",
      "617 4.783 0.109\n",
      "618 5.114 0.103\n",
      "619 4.909 0.061\n",
      "620 5.136 0.099\n",
      "621 4.991 0.124\n",
      "622 7.061 0.145\n",
      "623 4.313 0.299\n",
      "624 8.934 0.507\n",
      "625 5.534 0.364\n",
      "626 7.886 0.327\n",
      "627 6.786 0.124\n",
      "628 4.8 0.305\n",
      "629 8.222 0.384\n",
      "630 5.312 0.417\n",
      "631 6.761 0.243\n",
      "632 6.062 0.202\n",
      "633 6.534 0.312\n",
      "634 5.383 0.186\n",
      "635 6.411 0.214\n",
      "636 6.173 0.135\n",
      "637 6.862 0.201\n",
      "638 5.826 0.124\n",
      "639 4.965 0.201\n",
      "640 9.023 0.202\n",
      "641 6.742 0.172\n",
      "642 4.523 0.112\n",
      "643 9.902 0.296\n",
      "644 7.272 0.319\n",
      "645 4.384 0.08\n",
      "646 8.19 0.24\n",
      "647 7.798 0.072\n",
      "648 5.439 0.079\n",
      "649 5.17 0.086\n",
      "650 8.012 0.125\n",
      "651 6.577 0.139\n",
      "652 4.147 0.124\n",
      "653 9.424 0.259\n",
      "654 8.661 0.167\n",
      "655 5.071 0.103\n",
      "656 6.835 0.142\n",
      "657 6.027 0.191\n",
      "658 8.423 0.195\n",
      "659 6.8 0.105\n",
      "660 5.155 0.109\n",
      "661 10.571 0.306\n",
      "662 7.572 0.301\n",
      "663 4.274 0.08\n",
      "664 12.994 0.449\n",
      "665 9.264 0.871\n",
      "666 4.25 0.103\n",
      "667 12.561 0.711\n",
      "668 13.359 0.128\n",
      "669 8.912 0.074\n",
      "670 4.257 0.111\n",
      "671 10.632 0.532\n",
      "672 9.733 0.364\n",
      "673 6.323 0.15\n",
      "674 5.097 0.176\n",
      "675 6.565 0.235\n",
      "676 6.862 0.155\n",
      "677 5.251 0.136\n",
      "678 4.628 0.14\n",
      "679 6.092 0.26\n",
      "680 4.731 0.232\n",
      "681 6.273 0.265\n",
      "682 5.101 0.16\n",
      "683 4.5 0.256\n",
      "684 7.091 0.361\n",
      "685 3.878 0.34\n",
      "686 7.06 0.314\n",
      "687 6.561 0.096\n",
      "688 3.534 0.21\n",
      "689 6.197 0.306\n",
      "690 5.094 0.236\n",
      "691 3.744 0.415\n",
      "692 4.624 0.437\n",
      "693 4.57 0.374\n",
      "694 3.588 0.33\n",
      "695 5.407 0.296\n",
      "696 3.187 0.318\n",
      "697 5.942 0.305\n",
      "698 4.723 0.172\n",
      "699 3.998 0.1\n",
      "700 6.253 0.152\n",
      "701 4.073 0.14\n",
      "702 8.376 0.32\n",
      "703 1.726 0.61\n",
      "704 10.798 0.72\n",
      "705 6.359 0.777\n",
      "706 3.222 0.049\n",
      "707 7.369 0.295\n",
      "708 7.804 0.045\n",
      "709 5.929 0.089\n",
      "710 3.531 0.159\n",
      "711 5.822 0.226\n",
      "712 5.579 0.151\n",
      "713 3.456 0.256\n",
      "714 5.61 0.234\n",
      "715 4.275 0.181\n",
      "716 3.707 0.164\n",
      "717 5.036 0.194\n",
      "718 2.683 0.285\n",
      "719 6.496 0.321\n",
      "720 5.002 0.236\n",
      "721 3.339 0.105\n",
      "722 4.477 0.159\n",
      "723 5.739 0.094\n",
      "724 4.374 0.165\n",
      "725 3.648 0.094\n",
      "726 3.782 0.2\n",
      "727 4.997 0.152\n",
      "728 3.879 0.174\n",
      "729 3.662 0.141\n",
      "730 5.459 0.186\n",
      "731 5.253 0.096\n",
      "732 3.566 0.172\n",
      "733 7.618 0.262\n",
      "734 5.805 0.2\n",
      "735 3.081 0.177\n",
      "736 8.303 0.412\n",
      "737 5.339 0.378\n",
      "738 2.463 0.155\n",
      "739 10.079 0.52\n",
      "740 7.211 0.411\n",
      "741 3.286 0.153\n",
      "742 9.005 0.492\n",
      "743 7.789 0.244\n",
      "744 5.185 0.103\n",
      "745 4.352 0.176\n",
      "746 9.743 0.38\n",
      "747 6.16 0.724\n",
      "748 5.143 0.104\n",
      "749 6.433 0.155\n",
      "750 7.264 0.126\n",
      "751 4.71 0.125\n",
      "752 8.678 0.316\n",
      "753 2.922 0.678\n",
      "754 11.227 0.73\n",
      "755 7.726 0.637\n",
      "756 2.853 0.246\n",
      "757 8.127 0.49\n",
      "758 8.376 0.107\n",
      "759 3.662 0.367\n",
      "760 6.128 0.486\n",
      "761 5.161 0.193\n",
      "762 3.878 0.231\n",
      "763 4.184 0.143\n",
      "764 5.067 0.128\n",
      "765 5.198 0.099\n",
      "766 4.25 0.128\n",
      "767 4.263 0.134\n",
      "768 4.5 0.141\n",
      "769 4.651 0.072\n",
      "770 4.204 0.084\n",
      "771 4.399 0.127\n",
      "772 4.525 0.107\n",
      "773 4.221 0.097\n",
      "774 4.242 0.111\n",
      "775 5.0 0.148\n",
      "776 4.979 0.152\n",
      "777 4.297 0.141\n",
      "778 5.483 0.185\n",
      "779 3.839 0.196\n",
      "780 6.02 0.233\n",
      "781 4.989 0.152\n",
      "782 3.633 0.14\n",
      "783 3.716 0.173\n",
      "784 5.46 0.151\n",
      "785 4.62 0.159\n",
      "786 3.885 0.125\n",
      "787 4.965 0.151\n",
      "788 5.406 0.082\n",
      "789 4.905 0.105\n",
      "790 3.083 0.193\n",
      "791 6.934 0.21\n",
      "792 4.538 0.284\n",
      "793 3.823 0.119\n",
      "794 7.811 0.213\n",
      "795 6.458 0.156\n",
      "796 4.275 0.164\n",
      "797 8.581 0.243\n",
      "798 5.977 0.302\n",
      "799 5.004 0.176\n",
      "800 8.761 0.281\n",
      "801 7.579 0.148\n",
      "802 4.204 0.121\n",
      "803 10.178 0.487\n",
      "804 4.346 0.753\n",
      "805 5.41 0.188\n",
      "806 5.903 0.06\n",
      "807 5.147 0.06\n",
      "808 5.589 0.079\n",
      "809 4.835 0.091\n",
      "810 5.093 0.114\n",
      "811 4.475 0.189\n",
      "812 4.857 0.272\n",
      "813 3.129 0.254\n",
      "814 5.775 0.361\n",
      "815 4.985 0.162\n",
      "816 4.029 0.166\n",
      "817 4.844 0.135\n",
      "818 3.64 0.222\n",
      "819 7.159 0.186\n",
      "820 4.063 0.201\n",
      "821 4.358 0.216\n",
      "822 5.169 0.366\n",
      "823 4.402 0.119\n",
      "824 6.056 0.198\n",
      "825 3.343 0.23\n",
      "826 7.774 0.265\n",
      "827 4.961 0.239\n",
      "828 2.85 0.187\n",
      "829 8.805 0.297\n",
      "830 7.964 0.14\n",
      "831 5.504 0.071\n",
      "832 4.505 0.075\n",
      "833 4.254 0.119\n",
      "834 5.25 0.16\n",
      "835 5.78 0.127\n",
      "836 4.334 0.204\n",
      "837 5.892 0.145\n",
      "838 5.362 0.072\n",
      "839 4.461 0.148\n",
      "840 6.326 0.135\n",
      "841 4.964 0.169\n",
      "842 5.088 0.121\n",
      "843 5.828 0.078\n",
      "844 5.392 0.056\n",
      "845 4.28 0.172\n",
      "846 5.45 0.221\n",
      "847 5.921 0.079\n",
      "848 4.902 0.116\n",
      "849 4.774 0.163\n",
      "850 5.205 0.076\n",
      "851 5.252 0.112\n",
      "852 4.576 0.131\n",
      "853 3.908 0.259\n",
      "854 5.322 0.132\n",
      "855 4.933 0.096\n",
      "856 5.408 0.081\n",
      "857 5.473 0.093\n",
      "858 5.336 0.154\n",
      "859 4.745 0.177\n",
      "860 6.372 0.209\n",
      "861 3.906 0.225\n",
      "862 10.554 0.397\n",
      "863 4.87 0.654\n",
      "864 5.173 0.161\n",
      "865 9.088 0.276\n",
      "866 7.13 0.167\n",
      "867 6.097 0.296\n",
      "868 5.49 0.391\n",
      "869 3.722 0.374\n",
      "870 9.817 0.484\n",
      "871 7.083 0.368\n",
      "872 3.862 0.157\n",
      "873 9.342 0.475\n",
      "874 6.788 0.287\n",
      "875 2.972 0.133\n",
      "876 7.611 0.361\n",
      "877 6.389 0.149\n",
      "878 3.45 0.159\n",
      "879 9.228 0.391\n",
      "880 4.368 0.484\n",
      "881 4.595 0.13\n",
      "882 8.449 0.28\n",
      "883 6.886 0.09\n",
      "884 3.799 0.117\n",
      "885 5.65 0.222\n",
      "886 6.223 0.086\n",
      "887 4.105 0.115\n",
      "888 5.175 0.181\n",
      "889 4.426 0.155\n",
      "890 4.772 0.149\n",
      "891 2.85 0.22\n",
      "892 5.84 0.214\n",
      "893 4.66 0.234\n",
      "894 3.881 0.152\n",
      "895 4.401 0.137\n",
      "896 4.46 0.087\n",
      "897 4.701 0.116\n",
      "898 4.727 0.213\n",
      "899 5.09 0.093\n",
      "900 5.104 0.099\n",
      "901 3.517 0.169\n",
      "902 5.871 0.311\n",
      "903 4.637 0.201\n",
      "904 4.732 0.152\n",
      "905 3.416 0.286\n",
      "906 7.302 0.188\n",
      "907 4.106 0.235\n",
      "908 4.135 0.302\n",
      "909 5.403 0.226\n",
      "910 3.635 0.228\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(1000+1):\n",
    "    x_y = next(iter(trainAndTest.train_loader))\n",
    "    loss_G, loss_D = trainAndTest.train_one_batch(x_y)\n",
    "    loss_G, loss_D = round(loss_G, 3), round(loss_D, 3)\n",
    "    print(epoch, loss_G, loss_D)\n",
    "    \n",
    "    if epoch%100==0:\n",
    "        trainAndTest.save_model(epoch, loss_G, loss_D)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T12:58:22.998397Z",
     "start_time": "2020-11-29T12:58:22.809542Z"
    },
    "id": "W3iqevm3aypd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# trainAndTest.df_history.plot(x='epoch', y=['loss_D'])\n",
    "trainAndTest.df_history.plot(x='epoch', y=['loss_G', 'loss_D'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T12:52:18.803025Z",
     "start_time": "2020-11-29T12:52:18.792497Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_one_row_imgs(imgs):\n",
    "    fig=plt.figure(figsize=(8, 8))\n",
    "    columns = 5\n",
    "    rows = 1\n",
    "    for i in range(1, columns*rows +1):\n",
    "        img = imgs[i]\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img, interpolation='nearest')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T12:47:32.462433Z",
     "start_time": "2020-11-29T12:47:32.458881Z"
    },
    "id": "piHEYr4napLU",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# imgs = trainAndTest.sample_imgs(epoch=950)\n",
    "# trans_imgs = imgs.transpose([0, 2, 3, 1])\n",
    "# plt.imshow(trans_imgs[10], interpolation='nearest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T18:27:04.806313Z",
     "start_time": "2020-11-29T18:26:59.542913Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(0, 10000+1, 10000//20):\n",
    "    print('#'*50)\n",
    "    print('epoch' ,epoch)\n",
    "    imgs = trainAndTest.sample_imgs(epoch=epoch)\n",
    "    trans_imgs = imgs.transpose([0, 2, 3, 1])\n",
    "    plot_one_row_imgs(trans_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPOutNoe699qJzzrQBH/cmt",
   "collapsed_sections": [],
   "name": "GAN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
