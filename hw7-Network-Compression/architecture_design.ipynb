{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T10:20:43.295327Z",
     "start_time": "2020-08-23T10:20:43.236866Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import time\n",
    "from glob import glob\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='2' \n",
    "\n",
    "from torchsummary import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T10:07:07.259407Z",
     "start_time": "2020-08-23T10:07:07.250749Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_paths_and_labels(img_type='training', isLbael=True):\n",
    "    base_dir = '/workdir/home/feynman52/NTU-ML2020/hw3-Food-Classification-by-CNN/datasets'\n",
    "    paths = sorted(glob(os.path.join(base_dir, img_type, '*')))[:]\n",
    "    \n",
    "    if isLbael==True: \n",
    "        Y = [int(re.search('/(.{1,2})_', path).group(1)) for path in paths]\n",
    "        return paths, Y\n",
    "    else:\n",
    "        return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T10:07:07.385678Z",
     "start_time": "2020-08-23T10:07:07.262184Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9866, 9866, 3430, 3430, 3347)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_paths, y_train = get_paths_and_labels(img_type='training', isLbael=True)\n",
    "x_valid_paths, y_valid = get_paths_and_labels(img_type='validation', isLbael=True)\n",
    "x_test_paths = get_paths_and_labels(img_type='testing', isLbael=False)\n",
    "\n",
    "len(x_train_paths), len(y_train), len(x_valid_paths), len(y_valid), len(x_test_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T10:07:07.391073Z",
     "start_time": "2020-08-23T10:07:07.387453Z"
    }
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(), \n",
    "    transforms.RandomRotation(15), \n",
    "    transforms.ToTensor(), \n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),                                    \n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T10:07:07.436059Z",
     "start_time": "2020-08-23T10:07:07.392615Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImgDataset(Dataset):\n",
    "    def __init__(self, img_paths, labels=None, transform=None):\n",
    "        self.img_paths = img_paths\n",
    "        \n",
    "        self.labels = labels\n",
    "        if self.labels != None:\n",
    "            self.labels = torch.LongTensor(labels) ###\n",
    "            \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_paths[index]\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, (128, 128))\n",
    "        \n",
    "        if self.transform!=None: img = self.transform(img)\n",
    "            \n",
    "        if self.labels==None: \n",
    "            return img\n",
    "        else:\n",
    "            label = self.labels[index]\n",
    "            return img, label\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T10:07:07.496657Z",
     "start_time": "2020-08-23T10:07:07.440067Z"
    }
   },
   "outputs": [],
   "source": [
    "train_set = ImgDataset(x_train_paths, y_train, train_transform)\n",
    "valid_set = ImgDataset(x_valid_paths, y_valid, test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T10:07:07.564485Z",
     "start_time": "2020-08-23T10:07:07.500958Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 128, 128]), tensor(9))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = train_set[-1]\n",
    "x.shape, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T10:07:07.584796Z",
     "start_time": "2020-08-23T10:07:07.572589Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True) # shuffle select index\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T10:07:07.882907Z",
     "start_time": "2020-08-23T10:07:07.589066Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 3, 128, 128]), torch.Size([50]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = iter(train_loader)\n",
    "x_batch, y_batch = next(g)\n",
    "x_batch.shape, y_batch.shape\n",
    "x_batch.size(), y_batch.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T10:07:07.888470Z",
     "start_time": "2020-08-23T10:07:07.884723Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198, 69)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T10:07:07.945433Z",
     "start_time": "2020-08-23T10:07:07.889831Z"
    }
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n",
    "        # input 維度 [3, 128, 128]\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, 1, 1),  # [64, 128, 128]\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [64, 64, 64]\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, 1, 1), # [128, 64, 64]\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [128, 32, 32]\n",
    "\n",
    "            nn.Conv2d(128, 256, 3, 1, 1), # [256, 32, 32]\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [256, 16, 16]\n",
    "\n",
    "            nn.Conv2d(256, 512, 3, 1, 1), # [512, 16, 16]\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),       # [512, 8, 8]\n",
    "            \n",
    "            nn.Conv2d(512, 512, 3, 1, 1), # [512, 8, 8]\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),       # [512, 4, 4]\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512*4*4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 11)\n",
    "        )\n",
    "\n",
    "    def forward(self, in_):\n",
    "        x = self.cnn(in_)\n",
    "        #print(x.shape)\n",
    "        x = x.reshape(x.shape[0], -1) # x.shape = x.sise()\n",
    "        out_ = self.fc(x)\n",
    "        return out_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T10:37:53.761754Z",
     "start_time": "2020-08-23T10:37:53.579600Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 128, 128]           1,792\n",
      "       BatchNorm2d-2         [-1, 64, 128, 128]             128\n",
      "              ReLU-3         [-1, 64, 128, 128]               0\n",
      "         MaxPool2d-4           [-1, 64, 64, 64]               0\n",
      "            Conv2d-5          [-1, 128, 64, 64]          73,856\n",
      "       BatchNorm2d-6          [-1, 128, 64, 64]             256\n",
      "              ReLU-7          [-1, 128, 64, 64]               0\n",
      "         MaxPool2d-8          [-1, 128, 32, 32]               0\n",
      "            Conv2d-9          [-1, 256, 32, 32]         295,168\n",
      "      BatchNorm2d-10          [-1, 256, 32, 32]             512\n",
      "             ReLU-11          [-1, 256, 32, 32]               0\n",
      "        MaxPool2d-12          [-1, 256, 16, 16]               0\n",
      "           Conv2d-13          [-1, 512, 16, 16]       1,180,160\n",
      "      BatchNorm2d-14          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-15          [-1, 512, 16, 16]               0\n",
      "        MaxPool2d-16            [-1, 512, 8, 8]               0\n",
      "           Conv2d-17            [-1, 512, 8, 8]       2,359,808\n",
      "      BatchNorm2d-18            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-19            [-1, 512, 8, 8]               0\n",
      "        MaxPool2d-20            [-1, 512, 4, 4]               0\n",
      "           Linear-21                 [-1, 1024]       8,389,632\n",
      "             ReLU-22                 [-1, 1024]               0\n",
      "           Linear-23                  [-1, 512]         524,800\n",
      "             ReLU-24                  [-1, 512]               0\n",
      "           Linear-25                   [-1, 11]           5,643\n",
      "================================================================\n",
      "Total params: 12,833,803\n",
      "Trainable params: 12,833,803\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 49.59\n",
      "Params size (MB): 48.96\n",
      "Estimated Total Size (MB): 98.73\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = Classifier().cuda()\n",
    "summary(model, input_size=(3, 128, 128))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T13:28:34.959304Z",
     "start_time": "2020-08-28T13:28:34.931645Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1792/280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T10:39:48.778815Z",
     "start_time": "2020-08-23T10:39:48.753129Z"
    }
   },
   "outputs": [],
   "source": [
    "class ClassifierPrune(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ClassifierPrune, self).__init__()\n",
    "        \n",
    "        self.Conv2d_prune = nn.Sequential(\n",
    "        )\n",
    "        \n",
    "        self.cnn = nn.Sequential(\n",
    "            #nn.Conv2d(3, 64, 3, 1, 1),  # [64, 128, 128]\n",
    "            self.make_prune_cnn(3, 64, 3, 1, 1),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [64, 64, 64]\n",
    "\n",
    "            #nn.Conv2d(64, 128, 3, 1, 1), # [128, 64, 64]\n",
    "            self.make_prune_cnn(64, 128, 3, 1, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [128, 32, 32]\n",
    "\n",
    "            #nn.Conv2d(128, 256, 3, 1, 1), # [256, 32, 32]\n",
    "            self.make_prune_cnn(128, 256, 3, 1, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [256, 16, 16]\n",
    "\n",
    "            #nn.Conv2d(256, 512, 3, 1, 1), # [512, 16, 16]\n",
    "            self.make_prune_cnn(256, 512, 3, 1, 1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),       # [512, 8, 8]\n",
    "            \n",
    "            #nn.Conv2d(512, 512, 3, 1, 1), # [512, 8, 8]\n",
    "            self.make_prune_cnn(512, 512, 3, 1, 1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),       # [512, 4, 4]\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512*4*4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 11)\n",
    "        )\n",
    "\n",
    "    def make_prune_cnn(self, in_chs, out_chs, kernel_size, stride, padding):\n",
    "        prune_cnn = nn.Sequential(\n",
    "            nn.Conv2d(in_chs, in_chs, kernel_size, stride, padding, groups=in_chs), # depthwise\n",
    "            nn.Conv2d(in_chs, out_chs, 1) # pointwise\n",
    "        )\n",
    "        return prune_cnn\n",
    "        \n",
    "    def forward(self, in_):\n",
    "        x = self.cnn(in_)\n",
    "        x = x.reshape(x.shape[0], -1) \n",
    "        out_ = self.fc(x)\n",
    "        return out_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T11:07:19.773636Z",
     "start_time": "2020-08-23T11:07:19.759320Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.265734265734266"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1792)/(30+256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T10:39:50.323623Z",
     "start_time": "2020-08-23T10:39:50.135258Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 3, 128, 128]              30\n",
      "            Conv2d-2         [-1, 64, 128, 128]             256\n",
      "       BatchNorm2d-3         [-1, 64, 128, 128]             128\n",
      "              ReLU-4         [-1, 64, 128, 128]               0\n",
      "         MaxPool2d-5           [-1, 64, 64, 64]               0\n",
      "            Conv2d-6           [-1, 64, 64, 64]             640\n",
      "            Conv2d-7          [-1, 128, 64, 64]           8,320\n",
      "       BatchNorm2d-8          [-1, 128, 64, 64]             256\n",
      "              ReLU-9          [-1, 128, 64, 64]               0\n",
      "        MaxPool2d-10          [-1, 128, 32, 32]               0\n",
      "           Conv2d-11          [-1, 128, 32, 32]           1,280\n",
      "           Conv2d-12          [-1, 256, 32, 32]          33,024\n",
      "      BatchNorm2d-13          [-1, 256, 32, 32]             512\n",
      "             ReLU-14          [-1, 256, 32, 32]               0\n",
      "        MaxPool2d-15          [-1, 256, 16, 16]               0\n",
      "           Conv2d-16          [-1, 256, 16, 16]           2,560\n",
      "           Conv2d-17          [-1, 512, 16, 16]         131,584\n",
      "      BatchNorm2d-18          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-19          [-1, 512, 16, 16]               0\n",
      "        MaxPool2d-20            [-1, 512, 8, 8]               0\n",
      "           Conv2d-21            [-1, 512, 8, 8]           5,120\n",
      "           Conv2d-22            [-1, 512, 8, 8]         262,656\n",
      "      BatchNorm2d-23            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-24            [-1, 512, 8, 8]               0\n",
      "        MaxPool2d-25            [-1, 512, 4, 4]               0\n",
      "           Linear-26                 [-1, 1024]       8,389,632\n",
      "             ReLU-27                 [-1, 1024]               0\n",
      "           Linear-28                  [-1, 512]         524,800\n",
      "             ReLU-29                  [-1, 512]               0\n",
      "           Linear-30                   [-1, 11]           5,643\n",
      "================================================================\n",
      "Total params: 9,368,489\n",
      "Trainable params: 9,368,489\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 53.71\n",
      "Params size (MB): 35.74\n",
      "Estimated Total Size (MB): 89.64\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_prune = ClassifierPrune().cuda()\n",
    "summary(model_prune, input_size=(3, 128, 128))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T10:20:43.233960Z",
     "start_time": "2020-08-23T10:07:07.949428Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch = 1, time = 81, train_loss = 0.042, train_acc = 0.28, valid_loss = 0.041, valid_acc = 0.30\n",
      "epoch = 2, time = 81, train_loss = 0.036, train_acc = 0.38, valid_loss = 0.037, valid_acc = 0.35\n",
      "epoch = 3, time = 81, train_loss = 0.033, train_acc = 0.43, valid_loss = 0.034, valid_acc = 0.40\n",
      "epoch = 4, time = 80, train_loss = 0.031, train_acc = 0.46, valid_loss = 0.034, valid_acc = 0.41\n",
      "epoch = 5, time = 80, train_loss = 0.028, train_acc = 0.50, valid_loss = 0.032, valid_acc = 0.48\n",
      "epoch = 6, time = 80, train_loss = 0.027, train_acc = 0.53, valid_loss = 0.028, valid_acc = 0.50\n",
      "epoch = 7, time = 81, train_loss = 0.025, train_acc = 0.56, valid_loss = 0.032, valid_acc = 0.52\n",
      "epoch = 8, time = 80, train_loss = 0.023, train_acc = 0.59, valid_loss = 0.034, valid_acc = 0.48\n",
      "epoch = 9, time = 80, train_loss = 0.022, train_acc = 0.61, valid_loss = 0.032, valid_acc = 0.50\n",
      "epoch = 10, time = 80, train_loss = 0.021, train_acc = 0.64, valid_loss = 0.025, valid_acc = 0.59\n"
     ]
    }
   ],
   "source": [
    "print('train')\n",
    "\n",
    "model = Classifier().cuda()\n",
    "epochs = 10\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # initialize time\n",
    "    epoch_start_time = time.time()\n",
    "    # initialize metric\n",
    "    train_acc = 0.\n",
    "    valid_acc = 0.\n",
    "    train_loss = 0.\n",
    "    valid_loss = 0.\n",
    "    \n",
    "    # -----------------------\n",
    "    #  train \n",
    "    # -----------------------\n",
    "    model.train() ###\n",
    "    for (i, data) in enumerate(train_loader):\n",
    "        x, y = data[0].cuda(), data[1].cuda()\n",
    "        \n",
    "        # reset gradient !!!\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # y_hat, (-1,11)\n",
    "        y_hat = model(x)\n",
    "        \n",
    "        # loss\n",
    "        batch_loss = loss(y_hat, y)\n",
    "        \n",
    "        # gradient\n",
    "        batch_loss.backward()\n",
    "        \n",
    "        # update_weight\n",
    "        optimizer.step()\n",
    "        \n",
    "        # metric, acc, loss\n",
    "        label_hat = np.argmax(y_hat.cpu().data.numpy(), axis=1)\n",
    "        label = y.cpu().data.numpy()\n",
    "        match = (label_hat==label)\n",
    "        train_acc += sum(match)\n",
    "        train_loss += batch_loss.item()\n",
    "        \n",
    "\n",
    "    \n",
    "    # -----------------------\n",
    "    #  valid \n",
    "    # -----------------------\n",
    "    model.eval() ###\n",
    "    with torch.no_grad(): ###\n",
    "        for (i, data) in enumerate(valid_loader):\n",
    "            x, y = data[0].cuda(), data[1].cuda()\n",
    "\n",
    "            # y_hat\n",
    "            y_hat = model(x)\n",
    "\n",
    "            # loss\n",
    "            batch_loss = loss(y_hat, y)\n",
    "\n",
    "            # metric\n",
    "            label_hat = np.argmax(y_hat.cpu().data.numpy(), axis=1)\n",
    "            label = y.cpu().data.numpy()\n",
    "            match = (label_hat==label)\n",
    "            valid_acc += sum(match)\n",
    "\n",
    "            valid_loss += batch_loss.item()\n",
    "    \n",
    "    \n",
    "    # -----------------------\n",
    "    #  progress \n",
    "    # -----------------------\n",
    "    epoch += 1\n",
    "    t = time.time() - epoch_start_time\n",
    "    train_loss /= len(train_set)\n",
    "    valid_loss /= len(valid_set)\n",
    "    train_acc /= len(train_set)\n",
    "    valid_acc /= len(valid_set)\n",
    "\n",
    "    print('epoch = %d, time = %d, train_loss = %.3f, train_acc = %.2f, valid_loss = %.3f, valid_acc = %.2f'%(\n",
    "        epoch, t, train_loss, train_acc, valid_loss, valid_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T10:55:16.235053Z",
     "start_time": "2020-08-23T10:42:11.687651Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch = 1, time = 78, train_loss = 0.042, train_acc = 0.29, valid_loss = 0.044, valid_acc = 0.25\n",
      "epoch = 2, time = 78, train_loss = 0.034, train_acc = 0.41, valid_loss = 0.032, valid_acc = 0.43\n",
      "epoch = 3, time = 78, train_loss = 0.029, train_acc = 0.49, valid_loss = 0.036, valid_acc = 0.43\n",
      "epoch = 4, time = 78, train_loss = 0.026, train_acc = 0.55, valid_loss = 0.027, valid_acc = 0.54\n",
      "epoch = 5, time = 78, train_loss = 0.024, train_acc = 0.59, valid_loss = 0.028, valid_acc = 0.53\n",
      "epoch = 6, time = 78, train_loss = 0.022, train_acc = 0.62, valid_loss = 0.029, valid_acc = 0.52\n",
      "epoch = 7, time = 78, train_loss = 0.021, train_acc = 0.64, valid_loss = 0.027, valid_acc = 0.56\n",
      "epoch = 8, time = 78, train_loss = 0.019, train_acc = 0.67, valid_loss = 0.025, valid_acc = 0.60\n",
      "epoch = 9, time = 78, train_loss = 0.018, train_acc = 0.69, valid_loss = 0.023, valid_acc = 0.63\n",
      "epoch = 10, time = 78, train_loss = 0.017, train_acc = 0.70, valid_loss = 0.022, valid_acc = 0.64\n"
     ]
    }
   ],
   "source": [
    "print('train')\n",
    "\n",
    "model_prune_prune = ClassifierPrune().cuda()\n",
    "epochs = 10\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_prune.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # initialize time\n",
    "    epoch_start_time = time.time()\n",
    "    # initialize metric\n",
    "    train_acc = 0.\n",
    "    valid_acc = 0.\n",
    "    train_loss = 0.\n",
    "    valid_loss = 0.\n",
    "    \n",
    "    # -----------------------\n",
    "    #  train \n",
    "    # -----------------------\n",
    "    model_prune.train() ###\n",
    "    for (i, data) in enumerate(train_loader):\n",
    "        x, y = data[0].cuda(), data[1].cuda()\n",
    "        \n",
    "        # reset gradient !!!\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # y_hat, (-1,11)\n",
    "        y_hat = model_prune(x)\n",
    "        \n",
    "        # loss\n",
    "        batch_loss = loss(y_hat, y)\n",
    "        \n",
    "        # gradient\n",
    "        batch_loss.backward()\n",
    "        \n",
    "        # update_weight\n",
    "        optimizer.step()\n",
    "        \n",
    "        # metric, acc, loss\n",
    "        label_hat = np.argmax(y_hat.cpu().data.numpy(), axis=1)\n",
    "        label = y.cpu().data.numpy()\n",
    "        match = (label_hat==label)\n",
    "        train_acc += sum(match)\n",
    "        train_loss += batch_loss.item()\n",
    "        \n",
    "\n",
    "    \n",
    "    # -----------------------\n",
    "    #  valid \n",
    "    # -----------------------\n",
    "    model_prune.eval() ###\n",
    "    with torch.no_grad(): ###\n",
    "        for (i, data) in enumerate(valid_loader):\n",
    "            x, y = data[0].cuda(), data[1].cuda()\n",
    "\n",
    "            # y_hat\n",
    "            y_hat = model_prune(x)\n",
    "\n",
    "            # loss\n",
    "            batch_loss = loss(y_hat, y)\n",
    "\n",
    "            # metric\n",
    "            label_hat = np.argmax(y_hat.cpu().data.numpy(), axis=1)\n",
    "            label = y.cpu().data.numpy()\n",
    "            match = (label_hat==label)\n",
    "            valid_acc += sum(match)\n",
    "\n",
    "            valid_loss += batch_loss.item()\n",
    "    \n",
    "    \n",
    "    # -----------------------\n",
    "    #  progress \n",
    "    # -----------------------\n",
    "    epoch += 1\n",
    "    t = time.time() - epoch_start_time\n",
    "    train_loss /= len(train_set)\n",
    "    valid_loss /= len(valid_set)\n",
    "    train_acc /= len(train_set)\n",
    "    valid_acc /= len(valid_set)\n",
    "\n",
    "    print('epoch = %d, time = %d, train_loss = %.3f, train_acc = %.2f, valid_loss = %.3f, valid_acc = %.2f'%(\n",
    "        epoch, t, train_loss, train_acc, valid_loss, valid_acc))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
